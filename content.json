{"meta":{"title":"ctzzhang","subtitle":null,"description":null,"author":"Ctzzhang","url":"http://localhost:4000","root":"/"},"pages":[{"title":"关于","date":"2019-06-16T07:30:14.312Z","updated":"2019-06-16T07:30:14.312Z","comments":false,"path":"about/index.html","permalink":"http://localhost:4000/about/index.html","excerpt":"","text":"欢迎访问我的博客，我会保持不定期更新。/** * * ━━━━━━神兽出没━━━━━━┏┓ ┏┓┃ ┃ + +┃ ━ ┃ ++ + + +████━████ ┃ 🚂🚂🚂-&lt;-&lt; 欢迎访问 https://ctzzhang.github.io/┃ ┃ +┃ ┻ ┃ + +┃ ┃┗━┓ ┏━┛Code is far away from bug with the animal protecting┃ ┃ 神兽护体，永无bug┃ ┃ +┃ ┗━━━┓+┃ ┣┓ 📬 联系我：tzzhang021.com(at)163.com┃ ┏┛ + +┗┓┓┏━┳┓┏┛ +┃┫┫ ┃┫┫┗┻┛ ┗┻┛/"},{"title":"分类","date":"2019-06-16T07:30:14.382Z","updated":"2019-06-16T07:30:14.382Z","comments":false,"path":"categories/index.html","permalink":"http://localhost:4000/categories/index.html","excerpt":"","text":""},{"title":"书单","date":"2019-06-16T07:30:14.364Z","updated":"2019-06-16T07:30:14.364Z","comments":false,"path":"books/index.html","permalink":"http://localhost:4000/books/index.html","excerpt":"","text":""},{"title":"友情链接","date":"2019-06-16T07:30:14.380Z","updated":"2019-06-16T07:30:14.380Z","comments":true,"path":"links/index.html","permalink":"http://localhost:4000/links/index.html","excerpt":"","text":""},{"title":"Repositories","date":"2019-06-16T07:30:14.625Z","updated":"2019-06-16T07:30:14.625Z","comments":false,"path":"repository/index.html","permalink":"http://localhost:4000/repository/index.html","excerpt":"","text":""},{"title":"标签","date":"2019-06-16T07:30:14.367Z","updated":"2019-06-16T07:30:14.367Z","comments":false,"path":"tags/index.html","permalink":"http://localhost:4000/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"简析限流算法","slug":"简析限流算法","date":"2019-06-15T15:24:02.000Z","updated":"2019-06-17T04:40:38.950Z","comments":true,"path":"2019/06/15/简析限流算法/","link":"","permalink":"http://localhost:4000/2019/06/15/简析限流算法/","excerpt":"","text":"1.简介限流顾名思义是限制流量，限制流量的目的是为了保障服务稳定运行，避免服务被流量冲垮。当流量超出服务处理能力时，部分请求将会被限流组件拦截。被拦截的请求可能会被丢弃，如果是 C 端请求，那么这个请求可能会被导向指定的错误页上，而不是生硬的拒绝。这里我们丢弃掉一部分请求，以保证大部分请求可以正常响应。如果我们不这样做，那么服务崩溃后，所有请求都将无法响应了。当一台机器崩溃后，该机器的所有流量将由其他机器承担，这样就会造成剩余机器压力增大，进而导致奔溃，最后形成雪崩。除此之外，服务崩溃还会造成数据不一致的严重问题，特别是一些敏感数据。比如对于电商网站，如果后台服务准备将某笔订单数据存入数据库时，服务突然崩溃，导致数据没有落库。这个时候，开发同学就要想办法修订数据了。综上，我们可以看出来限流的重要性。接下来，我将向大家介绍三种常用的限流算法，分别是计数器、漏桶算法和令牌桶算法。下面我们从最简单的计数器开始说起。2.限流算法2.1 计数器计数器算法的思想很简单，每当一个请求到来时，我们就将计数器加一，当计数器数值超过阈值后，就拒绝余下请求。一秒钟后，我们将计数器清零，开始新一轮的计数。计数器算法简单粗暴，易于实现。但是缺点也是有的，也就是所谓的”突刺现象”。举例说明一下，假如我们给计数器设置的阈值为100。系统瞬间内（比如10毫秒内）有200个请求到来，这个时候计数器只能放过其中的100个请求，余下的100个请求全部被拒绝掉。如果第二秒内没有请求到来，那么系统就处于空闲状态。也就是上一秒忙的要死，这一秒又闲的要死。如果我们能用一个容器将剩余的100个请求缓存起来，待计数器重置后再将这些请求放出来。这样系统在这两秒内的吞吐量就由100变成了200，提升了一倍。基于这个思考，下面我们再来看看漏桶算法。2.2 漏桶算法漏桶算法由流量容器、流量入口和出口组成。其中流量出口流速即为我们期望的限速值，比如 100 QPS。漏桶算法除了具备限流能力，还具备流量整型功能。下面我们通过一张图来了解漏桶算法。如上图，流入漏桶流量的流速是不恒定的，经过漏桶限速后，流出流量的速度是恒定的。需要说明的是，漏桶的容量是有限的，一旦流入流量超出漏桶容量，这部分流量只能被丢弃了。漏桶是一个比较好的限流整型工具，不过漏桶不能处理突发流量，一些观点认为这是它的一个缺点。不过如果较起真来，我觉得这个缺点是不成立的。毕竟漏桶本就是用来平滑流量的，如果支持突发，那么输出流量反而不平滑了。如果要找一种能够支持突发流量的限流算法，那么令牌桶算法可以满足需求2.3 令牌桶算法令牌桶和漏桶颇有几分相似，只不过令牌通里存放的是令牌。它的运行过程是这样的，一个令牌工厂按照设定值定期向令牌桶发放令牌。当令牌桶满了后，多出的令牌会被丢弃掉。每当一个请求到来时，该请求对应的线程会从令牌桶中取令牌。初期由于令牌桶中存放了很多个令牌，因此允许多个请求同时取令牌。当桶中没有令牌后，无法获取到令牌的请求可以丢弃，或者重试。下面我们来看一下的令牌桶示意图：尽管令牌桶允许突发流量，但突发流量速率 R1 + 限流速率 R2 不能超过系统最大的处理能力 Rt，即 R1 + R2 ≤ Rt,否则会冲垮系统3.RateLimiter简介Google开源工具包Guava提供了限流工具类RateLimiter,该类基于令牌桶算法(Token Bucket)来完成限流,非常易于使用.RateLimiter经常用于限制对一些物理资源或者逻辑资源的访问速率.它支持两种获取permits接口,一种是如果拿不到立刻返回false,一种会阻塞等待一段时间看能不能拿到.RateLimiter和Java中的信号量(java.util.concurrent.Semaphore)类似,Semaphore通常用于限制并发量.源码注释中的一个例子,比如我们有很多任务需要执行,但是我们不希望每秒超过两个任务执行,那么我们就可以使用RateLimiter:1234567final RateLimiter rateLimiter = RateLimiter.create(2.0);void submitTasks(List&lt;Runnable&gt; tasks, Executor executor) &#123;for (Runnable task : tasks) &#123; rateLimiter.acquire(); // may wait executor.execute(task); &#125;&#125;另外一个例子,假如我们会产生一个数据流,然后我们想以每秒5kb的速度发送出去.我们可以每获取一个令牌(permit)就发送一个byte的数据,这样我们就可以通过一个每秒5000个令牌的RateLimiter来实现:12345final RateLimiter rateLimiter = RateLimiter.create(5000.0);void submitPacket(byte[] packet) &#123; rateLimiter.acquire(packet.length); networkService.send(packet);&#125;4.其他限流器ASP.NET版本的一个比较成熟限流器:WebApiThrottle 参考：http://www.cnblogs.com/mushroom/archive/2015/07/21/4659200.htmlhttps://github.com/springside/springside4/wiki/Rate-Limiterhttps://en.wikipedia.org/wiki/Token_buckethttps://en.wikipedia.org/wiki/Leaky_bucket5.总结以上就是本篇文章的全部内容。本篇文章简单分析几种常见限流算法的运行过程，限于能力原因，文章若有错误不妥之处还请指明。好了，本篇文章到这里就结束了，感谢大家的阅读。","categories":[{"name":"中间件","slug":"中间件","permalink":"http://localhost:4000/categories/中间件/"},{"name":"限流组件","slug":"中间件/限流组件","permalink":"http://localhost:4000/categories/中间件/限流组件/"}],"tags":[{"name":"限流组件","slug":"限流组件","permalink":"http://localhost:4000/tags/限流组件/"}]},{"title":"Java线程池的原理分析","slug":"Java线程池","date":"2019-06-15T14:25:02.000Z","updated":"2019-06-17T04:47:42.760Z","comments":true,"path":"2019/06/15/Java线程池/","link":"","permalink":"http://localhost:4000/2019/06/15/Java线程池/","excerpt":"","text":"Java线程池的原理分析1.简介随着并发的不断增加，单个线程的创建和销毁会带来大量的资源开销。通过线程池 我们可以方便的复用线程，避免了频繁创建和销毁线程所带来的开销。在应用上，线程池可应用在后端相关服务中。比如 Web 服务器，数据库服务器等。以 Web 服务器为例，假如 Web 服务器会收到大量短时的 HTTP 请求，如果此时我们简单的为每个 HTTP 请求创建一个处理线程，那么服务器的资源将会很快被耗尽。当然我们也可以自己去管理并复用已创建的线程，以限制资源的消耗量，但这样会使用程序的逻辑变复杂。好在，幸运的是，我们不必那样做。在 JDK 1.5 中，官方已经提供了强大的线程池工具类。通过使用这些工具类，我们可以用低廉的代价使用多线程技术。在Java用有一个Executors工具类，可以为我们创建一个线程池，其本质就是new了一个ThreadPoolExecutor对象。 觉得很有必要去学习一下线程池的相关原理。毕竟线程池除了要管理线程，还要管理任务，同时还要具备统计功能。所以多了解一点，还是可以扩充眼界的，同时也可以更为熟悉线程池技术。2.Executor继承关系线程池所采用的接口和类的结构如下图如上图，最顶层的接口 Executor 仅声明了一个方法execute。ExecutorService 接口在其父类接口基础上，声明了包含但不限于shutdown、submit、invokeAll、invokeAny 等方法。至于 ScheduledExecutorService 接口，则是声明了一些和定时任务相关的方法，比如 schedule和scheduleAtFixedRate。线程池的核心实现是在 ThreadPoolExecutor 类中，我们使用 Executors 调用newFixedThreadPool、newSingleThreadExecutor和newCachedThreadPool等方法创建线程池均是 ThreadPoolExecutor 类型。以上是对线程池继承体系的简单介绍，这里先让大家对线程池大致轮廓有一定的了解。接下来我会介绍一下线程池的实现原理，继续往下看吧。3.原理分析3.1核心关系分析3.1.1核心参数简介如上节所说，线程池的核心实现即 ThreadPoolExecutor 类。该类包含了几个核心属性，这些属性在可在构造方法进行初始化。在介绍核心属性前，我们先来看看 ThreadPoolExecutor 的构造方法，如下：12345678910111213141516171819202122public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue, ThreadFactory threadFactory, RejectedExecutionHandler handler) &#123; if (corePoolSize &lt; 0 || maximumPoolSize &lt;= 0 || maximumPoolSize &lt; corePoolSize || keepAliveTime &lt; 0) throw new IllegalArgumentException(); if (workQueue == null || threadFactory == null || handler == null) throw new NullPointerException(); this.corePoolSize = corePoolSize; this.maximumPoolSize = maximumPoolSize; this.workQueue = workQueue; this.keepAliveTime = unit.toNanos(keepAliveTime); this.threadFactory = threadFactory; this.handler = handler;&#125;如上所示，构造方法的参数即核心参数，这里我用一个表格来简要说明一下各个参数的意义。如下：参数说明corePoolSize核心线程数。当线程数小于该值时，线程池会优先创建新线程来执行新任务maximumPoolSize线程池所能维护的最大线程数keepAliveTime空闲线程的存活时间workQueue任务队列，用于缓存未执行的任务threadFactory线程工厂。可通过工厂为新建的线程设置更有意义的名字handler拒绝策略。当线程池和任务队列均处于饱和状态时，使用拒绝策略处理新任务。默认是 AbortPolicy，即直接抛出异常以上是各个参数的简介，下面我将会针对部分参数进行详细说明，继续往下看。3.1.2线程创建规则在 Java 线程池实现中，线程池所能创建的线程数量受限于 corePoolSize 和 maximumPoolSize 两个参数值。线程的创建时机则和 corePoolSize 以及 workQueue 两个参数有关。下面列举一下线程创建的4个规则（线程池中无空闲线程），如下：线程数量小于corePoolSize ，直接新创建线程处理任务线程数量大于等于corePoolSize ，workQueue 未满时，缓存新任务线程数量大于等于corePoolSize ，小于maximumPoolSize，且 workQueue 已满，则创建新线程处理新任务线程数量大于等于 maximumPoolSize，且 workQueue 已满，则使用拒绝策略处理新任务规则如下序号规则动作1线程数 &lt; corePoolSize创建新线程2线程数 &gt;= corePoolSize ，且 workQueue 未满缓存新任务3corePoolSize ≤ 线程数 ＜ maximumPoolSize，且 workQueue 已满创建新线程4线程数 ≥ maximumPoolSize，且 workQueue 已满使用拒绝策略处理3.1.3资源回收考虑到系统资源是有限的，对于线程池超出 corePoolSize 数量的空闲线程应进行回收操作。进行此操作存在一个问题，即回收时机。目前的实现方式是当线程空闲时间超过 keepAliveTime 后，进行回收。除了核心线程数之外的线程可以进行回收，核心线程内的空闲线程也可以进行回收。回收的前提是allowCoreThreadTimeOut属性被设置为 true，通过public void allowCoreThreadTimeOut(boolean) 方法可以设置属性值。3.1.4排队策略如3.1.2 线程创建规则一节中规则2所说，当线程数量大于等于 corePoolSize，workQueue 未满时，则缓存新任务。这里要考虑使用什么类型的容器缓存新任务，通过 JDK 文档介绍，我们可知道有3中类型的容器可供使用，分别是同步队列，有界队列和无界队列。对于有优先级的任务，这里还可以增加优先级队列。以上所介绍的4中类型的队列，对应的实现类如下：实现类类型说明SynchronousQueue同步队列该队列不存储元素，每个插入操作必须等待另一个线程调用移除操作，否则插入操作会一直阻塞ArrayBlockingQueue有界队列基于数组的阻塞队列，按照 FIFO 原则对元素进行排序LinkedBlockingQueue无界队列基于链表的阻塞队列，按照 FIFO 原则对元素进行排序PriorityBlockingQueue优先级队列具有优先级的阻塞队列3.1.5拒绝策略如3.1.2 线程创建规则一节中规则4所说，线程数量大于等于 maximumPoolSize，且 workQueue 已满，则使用拒绝策略处理新任务。Java 线程池提供了4中拒绝策略实现类，如下：实现类说明AbortPolicy （默认）丢弃新任务，并抛出 RejectedExecutionExceptionDiscardPolicy不做任何操作，直接丢弃新任务DiscardOldestPolicy丢弃队列队首的元素，并执行新任务CallerRunsPolicy由调用线程执行新任务以上4个拒绝策略中，AbortPolicy 是线程池实现类所使用的策略。我们也可以通过方法public void setRejectedExecutionHandler(RejectedExecutionHandler)修改线程池决绝策略。3.2 重要操作3.2.1线程的创建与复用在线程池的实现上，线程的创建是通过线程工厂接口ThreadFactory的实现类来完成的。默认情况下，线程池使用Executors.defaultThreadFactory()方法返回的线程工厂实现类。当然，我们也可以通过public void setThreadFactory(ThreadFactory)方法进行动态修改。具体细节这里就不多说了，并不复杂，大家可以自己去看下源码。在线程池中，线程的复用是线程池的关键所在。这就要求线程在执行完一个任务后，不能立即退出。对应到具体实现上，工作线程在执行完一个任务后，会再次到任务队列获取新的任务。如果任务队列中没有任务，且 keepAliveTime 也未被设置，工作线程则会被一致阻塞下去。通过这种方式即可实现线程复用。说完原理，再来看看线程的创建和复用的相关代码（基于 JDK 1.8），如下：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120private final class Worker extends AbstractQueuedSynchronizer implements Runnable &#123; /** * This class will never be serialized, but we provide a * serialVersionUID to suppress a javac warning. */ private static final long serialVersionUID = 6138294804551838833L; /** Thread this worker is running in. Null if factory fails. */ final Thread thread; /** Initial task to run. Possibly null. */ Runnable firstTask; /** Per-thread task counter */ volatile long completedTasks; /** * Creates with given first task and thread from ThreadFactory. * @param firstTask the first task (null if none) */ Worker(Runnable firstTask) &#123; setState(-1); // inhibit interrupts until runWorker this.firstTask = firstTask; // 调用线程工厂创建线程 this.thread = getThreadFactory().newThread(this); &#125; /** Delegates main run loop to outer runWorker */ public void run() &#123; //具体的执行 runWorker(this); &#125; // Lock methods // // The value 0 represents the unlocked state. // The value 1 represents the locked state. protected boolean isHeldExclusively() &#123; return getState() != 0; &#125; protected boolean tryAcquire(int unused) &#123; if (compareAndSetState(0, 1)) &#123; setExclusiveOwnerThread(Thread.currentThread()); return true; &#125; return false; &#125; protected boolean tryRelease(int unused) &#123; setExclusiveOwnerThread(null); setState(0); return true; &#125; public void lock() &#123; acquire(1); &#125; public boolean tryLock() &#123; return tryAcquire(1); &#125; public void unlock() &#123; release(1); &#125; public boolean isLocked() &#123; return isHeldExclusively(); &#125; void interruptIfStarted() &#123; Thread t; if (getState() &gt;= 0 &amp;&amp; (t = thread) != null &amp;&amp; !t.isInterrupted()) &#123; try &#123; t.interrupt(); &#125; catch (SecurityException ignore) &#123; &#125; &#125; &#125; &#125;//具体的执行final void runWorker(Worker w) &#123; Thread wt = Thread.currentThread(); Runnable task = w.firstTask; w.firstTask = null; w.unlock(); // allow interrupts boolean completedAbruptly = true; try &#123; // 循环从任务队列中获取新任务 while (task != null || (task = getTask()) != null) &#123; w.lock(); // If pool is stopping, ensure thread is interrupted; // if not, ensure thread is not interrupted. This // requires a recheck in second case to deal with // shutdownNow race while clearing interrupt if ((runStateAtLeast(ctl.get(), STOP) || (Thread.interrupted() &amp;&amp; runStateAtLeast(ctl.get(), STOP))) &amp;&amp; !wt.isInterrupted()) wt.interrupt(); try &#123; beforeExecute(wt, task); Throwable thrown = null; try &#123; // 执行新任务 task.run(); &#125; catch (RuntimeException x) &#123; thrown = x; throw x; &#125; catch (Error x) &#123; thrown = x; throw x; &#125; catch (Throwable x) &#123; thrown = x; throw new Error(x); &#125; finally &#123; afterExecute(task, thrown); &#125; &#125; finally &#123; task = null; w.completedTasks++; w.unlock(); &#125; &#125; completedAbruptly = false; &#125; finally &#123; // 线程退出后，进行后续处理 processWorkerExit(w, completedAbruptly); &#125; &#125;3.2.2 提交任务通常情况下，我们可以通过线程池的submit方法提交任务。被提交的任务可能会立即执行，也可能会被缓存或者被拒绝。任务的处理流程如下图所示：上面的流程图不是很复杂，下面再来看看流程图对应的代码，如下：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106+---- AbstractExecutorService.javapublic Future&lt;?&gt; submit(Runnable task) &#123; if (task == null) throw new NullPointerException(); // 创建任务 RunnableFuture&lt;Void&gt; ftask = newTaskFor(task, null); // 提交任务 execute(ftask); return ftask;&#125;+---- ThreadPoolExecutor.javapublic void execute(Runnable command) &#123; if (command == null) throw new NullPointerException(); int c = ctl.get(); // 如果工作线程数量 &lt; 核心线程数，则创建新线程 if (workerCountOf(c) &lt; corePoolSize) &#123; // 添加工作者对象 if (addWorker(command, true)) return; c = ctl.get(); &#125; // 缓存任务，如果队列已满，则 offer 方法返回 false。否则，offer 返回 true if (isRunning(c) &amp;&amp; workQueue.offer(command)) &#123; int recheck = ctl.get(); if (! isRunning(recheck) &amp;&amp; remove(command)) reject(command); else if (workerCountOf(recheck) == 0) addWorker(null, false); &#125; // 添加工作者对象，并在 addWorker 方法中检测线程数是否小于最大线程数 else if (!addWorker(command, false)) // 线程数 &gt;= 最大线程数，使用拒绝策略处理任务 reject(command);&#125;private boolean addWorker(Runnable firstTask, boolean core) &#123; retry: for (;;) &#123; int c = ctl.get(); int rs = runStateOf(c); // Check if queue empty only if necessary. if (rs &gt;= SHUTDOWN &amp;&amp; ! (rs == SHUTDOWN &amp;&amp; firstTask == null &amp;&amp; ! workQueue.isEmpty())) return false; for (;;) &#123; int wc = workerCountOf(c); // 检测工作线程数与核心线程数或最大线程数的关系 if (wc &gt;= CAPACITY || wc &gt;= (core ? corePoolSize : maximumPoolSize)) return false; if (compareAndIncrementWorkerCount(c)) break retry; c = ctl.get(); // Re-read ctl if (runStateOf(c) != rs) continue retry; // else CAS failed due to workerCount change; retry inner loop &#125; &#125; boolean workerStarted = false; boolean workerAdded = false; Worker w = null; try &#123; // 创建工作者对象，细节参考上一节所贴代码 w = new Worker(firstTask); final Thread t = w.thread; if (t != null) &#123; final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try &#123; int rs = runStateOf(ctl.get()); if (rs &lt; SHUTDOWN || (rs == SHUTDOWN &amp;&amp; firstTask == null)) &#123; if (t.isAlive()) // precheck that t is startable throw new IllegalThreadStateException(); // 将 worker 对象添加到 workers 集合中 workers.add(w); int s = workers.size(); // 更新 largestPoolSize 属性 if (s &gt; largestPoolSize) largestPoolSize = s; workerAdded = true; &#125; &#125; finally &#123; mainLock.unlock(); &#125; if (workerAdded) &#123; // 开始执行任务 t.start(); workerStarted = true; &#125; &#125; &#125; finally &#123; if (! workerStarted) addWorkerFailed(w); &#125; return workerStarted;&#125;3.2.3 关闭线程池我们可以通过shutdown和shutdownNow两个方法关闭线程池。两个方法的区别在于，shutdown 会将线程池的状态设置为SHUTDOWN，同时该方法还会中断空闲线程。shutdownNow 则会将线程池状态设置为STOP，并尝试中断所有的线程。中断线程使用的是Thread.interrupt方法，未响应中断方法的任务是无法被中断的。最后，shutdownNow 方法会将未执行的任务全部返回。调用 shutdown 和 shutdownNow 方法关闭线程池后，就不能再向线程池提交新任务了。对于处于关闭状态的线程池，会使用拒绝策略处理新提交的任务。4.几种线程池一般情况下，我们并不直接使用 ThreadPoolExecutor 类创建线程池，而是通过 Executors 工具类去构建线程池。通过 Executors 工具类，我们可以构造5中不同的线程池。下面通过一个表格简单介绍一下几种线程池，如下：构造方法说明newFixedThreadPool(int nThreads)构建包含固定线程数的线程池，默认情况下，空闲线程不会被回收newCachedThreadPool()构建线程数不定的线程池，线程数量随任务量变动，空闲线程存活时间超过60秒后会被回收newSingleThreadExecutor()构建线程数为1的线程池，等价于 newFixedThreadPool(1) 所构造出的线程池newScheduledThreadPool(int corePoolSize)构建核心线程数为 corePoolSize，可执行定时任务的线程池newSingleThreadScheduledExecutor()等价于 newScheduledThreadPool(1)5.总结一般需要根据任务的类型来配置线程池大小：如果是CPU密集型任务，就需要尽量压榨CPU，参考值可以设为 NCPU+1；如果是IO密集型任务，参考值可以设置为2*NCPU。当然，这只是一个参考值，具体的设置还需要根据实际情况进行调整，比如可以先将线程池大小设置为参考值，再观察任务运行情况和系统负载、资源利用率来进行适当调整。参考http://developer.51cto.com/art/201203/321885.htmhttp://blog.csdn.net/cutesource/article/details/6061229http://blog.csdn.net/xieyuooo/article/details/8718741","categories":[{"name":"Java基础","slug":"Java基础","permalink":"http://localhost:4000/categories/Java基础/"},{"name":"并发","slug":"Java基础/并发","permalink":"http://localhost:4000/categories/Java基础/并发/"}],"tags":[{"name":"锁","slug":"锁","permalink":"http://localhost:4000/tags/锁/"},{"name":"Java基础","slug":"Java基础","permalink":"http://localhost:4000/tags/Java基础/"},{"name":"开发","slug":"开发","permalink":"http://localhost:4000/tags/开发/"},{"name":"线程池","slug":"线程池","permalink":"http://localhost:4000/tags/线程池/"}]},{"title":"三种分布式锁实现","slug":"三种分布式锁实现","date":"2019-06-15T14:24:02.000Z","updated":"2019-06-17T04:45:11.514Z","comments":true,"path":"2019/06/15/三种分布式锁实现/","link":"","permalink":"http://localhost:4000/2019/06/15/三种分布式锁实现/","excerpt":"","text":"1.简介对于单机模式，多个线程对一个共享变量进行访问和修改时， 我们可以采用Java多线程进行处理，所有的请求会分配到本机的JVM内部，然后映射到操作系统进行处理。随着业务的发展，需要对服务进行集群，一个应用会部署到不同的机器上，共享数据会在不同机器的不同JVM内存，同时不同机器的中的变量也是不存在共享，也不具有可见性，如果不加以控制的话，处理的得到的结果也许不是我们所期望的值。为了保证同一时间内，同一个方法或者属性变量在高并发的情况下只会被同一个线程执行，在传统的单机模式下，采用Java并发处理包（如ReentrantLock或Synchronized)进行互斥控制即可。但是对于分布式集群系统中，由于多线程分布在不同的机器上，原单机部署情况下的并发控制锁策略失效，单纯的Java API并不能提供分布式锁的能力。为了解决这个问题就需要一种跨JVM的互斥机制来控制共享资源的访问，这就是分布式锁要解决的问题！2.分布式锁具备哪些条件在分布式系统环境下，一个方法在同一时间只能被一个机器的一个线程执行；高可用的获取锁与释放锁；高性能的获取锁与释放锁；具备可重入特性；具备锁失效机制，防止死锁；具备非阻塞锁特性，即没有获取到锁将直接返回获取锁失败。3.分布式锁的三种实现方式3.1 基于数据库实现3.1.1 基于数据库表的实现要实现分布式锁，最简单的方式是直接创建一张锁表，然后通过操作该表的数据来实现。当我们要锁住某个方法或资源时，我们就在该表中增加一条记录，想要释放锁的时候就删除这条记录。创建这样一张数据库表：12345678CREATE TABLE `methodLock` ( `id` int(11) NOT NULL AUTO_INCREMENT COMMENT &apos;主键&apos;, `method_name` varchar(64) NOT NULL DEFAULT &apos;&apos; COMMENT &apos;锁定的方法名&apos;, `desc` varchar(1024) NOT NULL DEFAULT &apos;备注信息&apos;, `update_time` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT &apos;保存数据时间，自动生成&apos;, PRIMARY KEY (`id`), UNIQUE KEY `uidx_method_name` (`method_name `) USING BTREE) ENGINE=InnoDB DEFAULT CHARSET=utf8 COMMENT=&apos;锁定中的方法&apos;;当我们想要锁住某个方法时，执行以下SQL：1insert into methodLock(method_name,desc) values (‘method_name’,‘desc’)因为我们对method_name做了唯一性约束，这里如果有多个请求同时提交到数据库的话，数据库会保证只有一个操作可以成功，那么我们就可以认为操作成功的那个线程获得了该方法的锁，可以执行方法体内容。当方法执行完毕之后，想要释放锁的话，需要执行以下Sql:1delete from methodLock where method_name =&apos;method_name&apos;上面这种简单的实现有以下几个问题：这把锁强依赖数据库的可用性，数据库是一个单点，一旦数据库挂掉，会导致业务系统不可用。这把锁没有失效时间，一旦解锁操作失败，就会导致锁记录一直在数据库中，其他线程无法再获得到锁。这把锁只能是非阻塞的，因为数据的insert操作，一旦插入失败就会直接报错。没有获得锁的线程并不会进入排队队列，要想再次获得锁就要再次触发获得锁操作。这把锁是非重入的，同一个线程在没有释放锁之前无法再次获得该锁。因为数据中数据已经存在了。针对上面的问题，可以采用以下方式数据库是单点？搞两个数据库，数据之前双向同步。一旦挂掉快速切换到备库上。没有失效时间？只要做一个定时任务，每隔一定时间把数据库中的超时数据清理一遍。非阻塞的？搞一个while循环，直到insert成功再返回成功。非重入的？在数据库表中加个字段，记录当前获得锁的机器的主机信息和线程信息，那么下次再获取锁的时候先查询数据库，如果当前机器的主机信息和线程信息在数据库可以查到的话，直接把锁分配给他就可以了。3.1.2 基于数据库表的排他锁除了可以通过增删操作数据表中的记录以外，其实还可以借助数据中自带的锁来实现分布式的锁。我们还用刚刚创建的那张数据库表。可以通过数据库的排他锁来实现分布式锁。 基于MySql的InnoDB引擎，可以使用以下方法来实现加锁操作：123456789101112131415public boolean lock()&#123; connection.setAutoCommit(false) while(true)&#123; try&#123; result = select * from methodLock where method_name=xxx for update; if(result==null)&#123; return true; &#125; &#125;catch(Exception e)&#123; &#125; sleep(1000); &#125; return false;&#125;在查询语句后面增加for update，数据库会在查询过程中给数据库表增加排他锁（这里再多提一句，InnoDB引擎在加锁的时候，只有通过索引进行检索的时候才会使用行级锁，否则会使用表级锁。这里我们希望使用行级锁，就要给method_name添加索引，值得注意的是，这个索引一定要创建成唯一索引，否则会出现多个重载方法之间无法同时被访问的问题。重载方法的话建议把参数类型也加上。）。当某条记录被加上排他锁之后，其他线程无法再在该行记录上增加排他锁。我们可以认为获得排它锁的线程即可获得分布式锁，当获取到锁之后，可以执行方法的业务逻辑，执行完方法之后，再通过以下方法解锁：123public void unlock()&#123; connection.commit();&#125;通过connection.commit()操作来释放锁。这种方法可以有效的解决上面提到的无法释放锁和阻塞锁的问题。阻塞锁？ for update语句会在执行成功后立即返回，在执行失败时一直处于阻塞状态，直到成功。锁定之后服务宕机，无法释放？使用这种方式，服务宕机之后数据库会自己把锁释放掉。但是还是无法直接解决数据库单点和可重入问题。这里还可能存在另外一个问题，虽然我们对method_name 使用了唯一索引，并且显示使用for update来使用行级锁。但是，MySql会对查询进行优化，即便在条件中使用了索引字段，但是否使用索引来检索数据是由 MySQL 通过判断不同执行计划的代价来决定的，如果 MySQL 认为全表扫效率更高，比如对一些很小的表，它就不会使用索引，这种情况下 InnoDB 将使用表锁，而不是行锁。如果发生这种情况就悲剧了。还有一个问题，就是我们要使用排他锁来进行分布式锁的lock，那么一个排他锁长时间不提交，就会占用数据库连接。一旦类似的连接变得多了，就可能把数据库连接池撑爆3.1.3总结总结一下使用数据库来实现分布式锁的方式，这两种方式都是依赖数据库的一张表，一种是通过表中的记录的存在情况确定当前是否有锁存在，另外一种是通过数据库的排他锁来实现分布式锁。数据库实现分布式锁的优点是直接借助数据库，容易理解，方便使用。但是会有各种各样的问题，在解决问题的过程中会使整个方案变得越来越复杂，另外操作操作数据库需要一定的开销，性能问题需要考虑。使用数据库的行级锁并不一定靠谱，尤其是当我们的锁表并不大的时候。3.2 基于redis实现3.2.1 加锁代码代码如下1234567891011121314151617181920212223242526public class RedisTool &#123; private static final String LOCK_SUCCESS = \"OK\"; private static final String SET_IF_NOT_EXIST = \"NX\"; private static final String SET_WITH_EXPIRE_TIME = \"PX\"; /** * 尝试获取分布式锁 * @param jedis Redis客户端 * @param lockKey 锁 * @param requestId 请求标识 * @param expireTime 超期时间 * @return 是否获取成功 */ public static boolean tryGetDistributedLock(Jedis jedis, String lockKey, String requestId, int expireTime) &#123; String result = jedis.set(lockKey, requestId, SET_IF_NOT_EXIST, SET_WITH_EXPIRE_TIME, expireTime); if (LOCK_SUCCESS.equals(result)) &#123; return true; &#125; return false; &#125;&#125;可以看到，我们加锁就一行代码：jedis.set(String key, String value, String nxxx, String expx, int time)，这个set()方法一共有五个形参：第一个为key，我们使用key来当锁，因为key是唯一的。第二个为value，我们传的是requestId，很多童鞋可能不明白，有key作为锁不就够了吗，为什么还要用到value？原因就是我们在上面讲到可靠性时，分布式锁要满足第四个条件解铃还须系铃人，通过给value赋值为requestId，我们就知道这把锁是哪个请求加的了，在解锁的时候就可以有依据。requestId可以使用UUID.randomUUID().toString()方法生成。第三个为nxxx，这个参数我们填的是NX，意思是SET IF NOT EXIST，即当key不存在时，我们进行set操作；若key已经存在，则不做任何操作；第四个为expx，这个参数我们传的是PX，意思是我们要给这个key加一个过期的设置，具体时间由第五个参数决定。第五个为time，与第四个参数相呼应，代表key的过期时间。总的来说，执行上面的set()方法就只会导致两种结果：1. 当前没有锁（key不存在），那么就进行加锁操作，并对锁设置个有效期，同时value表示加锁的客户端。2. 已有锁存在，不做任何操作。心细的童鞋就会发现了，我们的加锁代码满足我们可靠性里描述的三个条件。首先，set()加入了NX参数，可以保证如果已有key存在，则函数不会调用成功，也就是只有一个客户端能持有锁，满足互斥性。其次，由于我们对锁设置了过期时间，即使锁的持有者后续发生崩溃而没有解锁，锁也会因为到了过期时间而自动解锁（即key被删除），不会发生死锁。最后，因为我们将value赋值为requestId，代表加锁的客户端请求标识，那么在客户端在解锁的时候就可以进行校验是否是同一个客户端。由于我们只考虑Redis单机部署的场景，所以容错性我们暂不考虑。比较常见的错误示例就是使用jedis.setnx()和jedis.expire()组合实现加锁，代码如下：123456789public static void wrongGetLock1(Jedis jedis, String lockKey, String requestId, int expireTime) &#123; Long result = jedis.setnx(lockKey, requestId); if (result == 1) &#123; // 若在这里程序突然崩溃，则无法设置过期时间，将发生死锁 jedis.expire(lockKey, expireTime); &#125;&#125;setnx()方法作用就是SET IF NOT EXIST，expire()方法就是给锁加一个过期时间。乍一看好像和前面的set()方法结果一样，然而由于这是两条Redis命令，不具有原子性，如果程序在执行完setnx()之后突然崩溃，导致锁没有设置过期时间。那么将会发生死锁。网上之所以有人这样实现，是因为低版本的jedis并不支持多参数的set()方法。3.2.2解锁代码代码如下123456789101112131415161718192021222324public class RedisTool &#123; private static final Long RELEASE_SUCCESS = 1L; /** * 释放分布式锁 * @param jedis Redis客户端 * @param lockKey 锁 * @param requestId 请求标识 * @return 是否释放成功 */ public static boolean releaseDistributedLock(Jedis jedis, String lockKey, String requestId) &#123; String script = \"if redis.call('get', KEYS[1]) == ARGV[1] then return redis.call('del', KEYS[1]) else return 0 end\"; Object result = jedis.eval(script, Collections.singletonList(lockKey), Collections.singletonList(requestId)); if (RELEASE_SUCCESS.equals(result)) &#123; return true; &#125; return false; &#125;&#125;从上面可以看到，我们解锁只需要两行代码就搞定了！第一行代码，我们写了一个简单的Lua脚本代码，上一次见到这个编程语言还是在《黑客与画家》里，没想到这次居然用上了。第二行代码，我们将Lua代码传到jedis.eval()方法里，并使参数KEYS[1]赋值为lockKey，ARGV[1]赋值为requestId。eval()方法是将Lua代码交给Redis服务端执行。那么这段Lua代码的功能是什么呢？其实很简单，首先获取锁对应的value值，检查是否与requestId相等，如果相等则删除锁（解锁）。那么为什么要使用Lua语言来实现呢？因为要确保上述操作是原子性的 。那么为什么执行eval()方法可以确保原子性，源于Redis的特性。简单来说，就是在eval命令执行Lua代码的时候，Lua代码将被当成一个命令去执行，并且直到eval命令执行完成，Redis才会执行其他命令。最常见的解锁代码就是直接使用jedis.del()方法删除锁，这种不先判断锁的拥有者而直接解锁的方式，会导致任何客户端都可以随时进行解锁，即使这把锁不是它的。3.2.3总结如何使用Java代码正确实现Redis分布式锁，对于加锁和解锁也分别给出了两个比较经典的错误。其实想要通过Redis实现分布式锁并不难，只要保证能满足可靠性里的四个条件。互联网虽然给我们带来了方便，只要有问题就可以google，然而网上的答案一定是对的吗？其实不然，所以我们更应该时刻保持着质疑精神，多想多验证。如果你的项目中Redis是多机部署的，那么可以尝试使用Redisson实现分布式锁。3.3 基于zookeeper实现基于zookeeper临时有序节点可以实现的分布式锁。大致思想即为：每个客户端对某个方法加锁时，在zookeeper上的与该方法对应的指定节点的目录下，生成一个唯一的瞬时有序节点。 判断是否获取锁的方式很简单，只需要判断有序节点中序号最小的一个。 当释放锁的时候，只需将这个瞬时节点删除即可。同时，其可以避免服务宕机导致的锁无法释放，而产生的死锁问题。来看下Zookeeper能不能解决前面提到的问题。锁无法释放？使用Zookeeper可以有效的解决锁无法释放的问题，因为在创建锁的时候，客户端会在ZK中创建一个临时节点，一旦客户端获取到锁之后突然挂掉（Session连接断开），那么这个临时节点就会自动删除掉。其他客户端就可以再次获得锁。非阻塞锁？使用Zookeeper可以实现阻塞的锁，客户端可以通过在ZK中创建顺序节点，并且在节点上绑定监听器，一旦节点有变化，Zookeeper会通知客户端，客户端可以检查自己创建的节点是不是当前所有节点中序号最小的，如果是，那么自己就获取到锁，便可以执行业务逻辑了。不可重入？使用Zookeeper也可以有效的解决不可重入的问题，客户端在创建节点的时候，把当前客户端的主机信息和线程信息直接写入到节点中，下次想要获取锁的时候和当前最小的节点中的数据比对一下就可以了。如果和自己的信息一样，那么自己直接获取到锁，如果不一样就再创建一个临时的顺序节点，参与排队。单点问题？使用Zookeeper可以有效的解决单点问题，ZK是集群部署的，只要集群中有半数以上的机器存活，就可以对外提供服务。可以直接使用zookeeper第三方库Curator客户端，这个客户端中封装了一个可重入的锁服务。123456789101112131415161718public boolean tryLock(long timeout, TimeUnit unit) throws InterruptedException &#123; try &#123; return interProcessMutex.acquire(timeout, unit); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; return true;&#125;public boolean unlock() &#123; try &#123; interProcessMutex.release(); &#125; catch (Throwable e) &#123; log.error(e.getMessage(), e); &#125; finally &#123; executorService.schedule(new Cleaner(client, path), delayTimeForClean, TimeUnit.MILLISECONDS); &#125; return true;&#125;Curator提供的InterProcessMutex是分布式锁的实现。acquire方法用户获取锁，release方法用于释放锁。使用ZK实现的分布式锁好像完全符合了本文开头我们对一个分布式锁的所有期望。但是，其实并不是，Zookeeper实现的分布式锁其实存在一个缺点，那就是性能上可能并没有缓存服务那么高。因为每次在创建锁和释放锁的过程中，都要动态创建、销毁瞬时节点来实现锁功能。ZK中创建和删除节点只能通过Leader服务器来执行，然后将数据同不到所有的Follower机器上。其实，使用Zookeeper也有可能带来并发问题，只是并不常见而已。考虑这样的情况，由于网络抖动，客户端可ZK集群的session连接断了，那么zk以为客户端挂了，就会删除临时节点，这时候其他客户端就可以获取到分布式锁了。就可能产生并发问题。这个问题不常见是因为zk有重试机制，一旦zk集群检测不到客户端的心跳，就会重试，Curator客户端支持多种重试策略。多次重试之后还不行的话才会删除临时节点。（所以，选择一个合适的重试策略也比较重要，要在锁的粒度和并发之间找一个平衡。）使用Zookeeper实现分布式锁的优点有效的解决单点问题，不可重入问题，非阻塞问题以及锁无法释放的问题。实现起来较为简单。使用Zookeeper实现分布式锁的缺点性能上不如使用缓存实现分布式锁。 需要对ZK的原理有所了解。4. 总结上面几种方式，哪种方式都无法做到完美。就像CAP一样，在复杂性、可靠性、性能等方面无法同时满足，所以，根据不同的应用场景选择最适合自己的才是王道。从理解的难易程度角度（从低到高）数据库 &gt; 缓存 &gt; Zookeeper从实现的复杂性角度（从低到高）Zookeeper &gt;= 缓存 &gt; 数据库从性能角度（从高到低）缓存 &gt; Zookeeper &gt;= 数据库从可靠性角度（从高到低）Zookeeper &gt; 缓存 &gt; 数据库参考https://blog.csdn.net/wuzhiwei549/article/details/80692278https://www.hollischuang.com/archives/1716","categories":[{"name":"中间件","slug":"中间件","permalink":"http://localhost:4000/categories/中间件/"},{"name":"分布式","slug":"中间件/分布式","permalink":"http://localhost:4000/categories/中间件/分布式/"}],"tags":[{"name":"中间件","slug":"中间件","permalink":"http://localhost:4000/tags/中间件/"},{"name":"分布式","slug":"分布式","permalink":"http://localhost:4000/tags/分布式/"},{"name":"锁","slug":"锁","permalink":"http://localhost:4000/tags/锁/"}]},{"title":"Hello World","slug":"hello-world","date":"2019-06-14T13:48:34.388Z","updated":"2019-06-16T07:30:14.246Z","comments":true,"path":"2019/06/14/hello-world/","link":"","permalink":"http://localhost:4000/2019/06/14/hello-world/","excerpt":"","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub.Quick StartCreate a new post1$ hexo new \"My New Post\"More info: WritingRun server1$ hexo serverMore info: ServerGenerate static files1$ hexo generateMore info: GeneratingDeploy to remote sites1$ hexo deployMore info: Deployment","categories":[],"tags":[]}]}