{"meta":{"title":"ctzzhang","subtitle":null,"description":null,"author":"Ctzzhang","url":"http://localhost:4000","root":"/"},"pages":[{"title":"关于","date":"2019-06-16T07:30:14.312Z","updated":"2019-06-16T07:30:14.312Z","comments":false,"path":"about/index.html","permalink":"http://localhost:4000/about/index.html","excerpt":"","text":"欢迎访问我的博客，我会保持不定期更新。/** * * ━━━━━━神兽出没━━━━━━┏┓ ┏┓┃ ┃ + +┃ ━ ┃ ++ + + +████━████ ┃ 🚂🚂🚂-&lt;-&lt; 欢迎访问 https://ctzzhang.github.io/┃ ┃ +┃ ┻ ┃ + +┃ ┃┗━┓ ┏━┛Code is far away from bug with the animal protecting┃ ┃ 神兽护体，永无bug┃ ┃ +┃ ┗━━━┓+┃ ┣┓ 📬 联系我：tzzhang021.com(at)163.com┃ ┏┛ + +┗┓┓┏━┳┓┏┛ +┃┫┫ ┃┫┫┗┻┛ ┗┻┛/"},{"title":"分类","date":"2019-06-16T07:30:14.382Z","updated":"2019-06-16T07:30:14.382Z","comments":false,"path":"categories/index.html","permalink":"http://localhost:4000/categories/index.html","excerpt":"","text":""},{"title":"书单","date":"2019-06-16T07:30:14.364Z","updated":"2019-06-16T07:30:14.364Z","comments":false,"path":"books/index.html","permalink":"http://localhost:4000/books/index.html","excerpt":"","text":""},{"title":"友情链接","date":"2019-06-16T07:30:14.380Z","updated":"2019-06-16T07:30:14.380Z","comments":true,"path":"links/index.html","permalink":"http://localhost:4000/links/index.html","excerpt":"","text":""},{"title":"Repositories","date":"2019-06-16T07:30:14.625Z","updated":"2019-06-16T07:30:14.625Z","comments":false,"path":"repository/index.html","permalink":"http://localhost:4000/repository/index.html","excerpt":"","text":""},{"title":"标签","date":"2019-06-16T07:30:14.367Z","updated":"2019-06-16T07:30:14.367Z","comments":false,"path":"tags/index.html","permalink":"http://localhost:4000/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"Redis 基数树","slug":"Redis-基数树","date":"2019-06-19T14:41:33.000Z","updated":"2019-06-19T15:30:53.948Z","comments":true,"path":"2019/06/19/Redis-基数树/","link":"","permalink":"http://localhost:4000/2019/06/19/Redis-基数树/","excerpt":"","text":"Redis 基数树1. 简介Rax 是 Redis 内部比较特殊的一个数据结构，它是一个有序字典树 (基数树 Radix Tree)，按照 key 的字典序排列，支持快速地定位、插入和删除操作。Redis 五大基础数据结构里面，能作为字典使用的有 hash 和 zset。hash 不具备排序功能，zset 则是按照 score 进行排序的。rax 跟 zset 的不同在于它是按照 key 进行排序的。Redis 作者认为 rax 的结构非常易于理解，但是实现却有相当的复杂度，需要考虑很多的边界条件，需要处理节点的分裂、合并，一不小心就会出错。2. 应用你可以将一本英语字典看成一棵 radix tree，它所有的单词都是按照字典序进行排列，每个词汇都会附带一个解释，这个解释就是 key 对应的 value。有了这棵树，你就可以快速地检索单词，还可以查询以某个前缀开头的单词有哪些。你也可以将公安局的人员档案信息看成一棵 radix tree，它的 key 是每个人的身份证号，value 是这个人的履历。因为身份证号的编码的前缀是按照地区进行一级一级划分的，这点和单词非常类似。有了这棵树，你就可以快速地定位出人员档案，还可以快速查询出某个小片区都有哪些人。Radix tree 还可以应用于时间序列应用，key 为时间戳，value 为发生在具体时间的事件内容。因为时间戳的编码也是按照【年月日时分秒毫秒微秒纳秒】进行一级一级划分的，所以它也可以使用字典序来排序。有了这棵数，我们就可以快速定位出某个具体时间发生了什么事，也可以查询出一段时间内都有哪些事发生。我们经常使用的 Web 服务器的 Router 它也是一棵 radix tree。这棵树上挂满了 URL 规则，每个 URL 规则上都会附上一个请求处理器。当一个请求到来时，我们拿这个请求的 URL 沿着树进行遍历，找到相应的请求处理器来处理。因为 URL 中可能存在正则 pattern，而且同一层的节点对顺序没有要求，所以它不算是一棵严格的 radix tree。123456789101112131415161718# golang 的 HttpRouter 库The router relies on a tree structure which makes heavy use of *common prefixes*it is basically a *compact* [*prefix tree*](https://en.wikipedia.org/wiki/Trie)(or just [*Radix tree*](https://en.wikipedia.org/wiki/Radix_tree)).Nodes with a common prefix also share a common parent.Here is a short example what the routing tree for the `GET` request method could look like:Priority Path Handle9 \\ *&lt;1&gt;3 ├s nil2 |├earch\\ *&lt;2&gt;1 |└upport\\ *&lt;3&gt;2 ├blog\\ *&lt;4&gt;1 | └:post nil1 | └\\ *&lt;5&gt;2 ├about-us\\ *&lt;6&gt;1 | └team\\ *&lt;7&gt;1 └contact\\ *&lt;8&gt;Rax 被用在 Redis Stream 结构里面用于存储消息队列，在 Stream 里面消息 ID 的前缀是时间戳 + 序号，这样的消息可以理解为时间序列消息。使用 Rax 结构进行存储就可以快速地根据消息 ID 定位到具体的消息，然后继续遍历指定消息之后的所有消息。3. 结构rax 中有非常多的节点，根节点、叶节点和中间节点，有些中间节点带有 value，有些中间节点纯粹是结构性需要没有对应的 value。1234567struct raxNode &#123;int&lt;1&gt; isKey; // 是否没有 key，没有 key 的是根节点int&lt;1&gt; isNull; // 是否没有对应的 value，无意义的中间节点int&lt;1&gt; isCompressed; // 是否压缩存储，这个压缩的概念比较特别int&lt;29&gt; size; // 子节点的数量或者是压缩字符串的长度 (isCompressed)byte[] data; // 路由键、子节点指针、value 都在这里&#125;rax 是一棵比较特殊的 radix tree，它在结构上不是标准的 radix tree。如果一个中间节点有多个子节点，那么路由键就只是一个字符。如果只有一个子节点，那么路由键就是一个字符串。后者就是所谓的「压缩」形式，多个字符压在一起的字符串。比如前面的那棵字典树在 Rax 算法中将呈现出如下结构：图中的深蓝色节点就是「压缩」节点。接下来我们再细看raxNode.data里面存储的到底是什么东西，它是一个比较复杂的结构，按照压缩与否分为两种结构压缩结构 子节点如果只有一个，那就是压缩结构，data 字段如下伪代码所示：1234567struct data &#123;optional struct &#123; // 取决于 header 的 size 字段是否为零byte[] childKey; // 路由键raxNode* childNode; // 子节点指针&#125; child;optional string value; // 取决于 header 的 isNull 字段&#125;如果是叶子节点，child 字段就不存在。如果是无意义的中间节点 (isNull)，那么 value 字段就不存在。非压缩节点 如果子节点有多个，那就不是压缩结构，存在多个路由键，一个键是一个字符。12345struct data &#123;byte[] childKeys; // 路由键字符列表raxNode*[] childNodes; // 多个子节点指针optional string value; // 取决于 header 的 isNull 字段&#125;也许你会想到如果子节点只有一个，并且路由键字符串的长度为 1 呢，那到底算压缩还是非压缩？仔细思考一下，在这种情况下，压缩和非压缩在数据结构表现形式上是一样的，不管 isCompressed 是 0 还好是 1，结构都是一样的。","categories":[{"name":"Redis","slug":"Redis","permalink":"http://localhost:4000/categories/Redis/"},{"name":"源码","slug":"Redis/源码","permalink":"http://localhost:4000/categories/Redis/源码/"}],"tags":[]},{"title":"Redis 紧凑列表结构","slug":"Redis-紧凑列表结构","date":"2019-06-19T14:37:42.000Z","updated":"2019-06-19T15:30:42.573Z","comments":true,"path":"2019/06/19/Redis-紧凑列表结构/","link":"","permalink":"http://localhost:4000/2019/06/19/Redis-紧凑列表结构/","excerpt":"","text":"Redis 紧凑列表结构1. 简介Redis 5.0 又引入了一个新的数据结构 listpack，它是对 ziplist 结构的改进，在存储空间上会更加节省，而且结构上也比 ziplist 要精简。它的整体形式和 ziplist 还是比较接近的，如果你认真阅读了 ziplist 的内部结构分析，那么 listpack 也是比较容易理解的。123456struct listpack&lt;T&gt; &#123;int32 total_bytes; // 占用的总字节数int16 size; // 元素个数T[] entries; // 紧凑排列的元素列表int8 end; // 同 zlend 一样，恒为 0xFF&#125;首先这个 listpack 跟 ziplist 的结构几乎一摸一样，只是少了一个zltail_offset字段。ziplist 通过这个字段来定位出最后一个元素的位置，用于逆序遍历。不过 listpack 可以通过其它方式来定位出最后一个元素的位置，所以zltail_offset字段就省掉了。12345struct lpentry &#123;int&lt;var&gt; encoding;optional byte[] content;int&lt;var&gt; length;&#125;元素的结构和 ziplist 的元素结构也很类似，都是包含三个字段。不同的是长度字段放在了元素的尾部，而且存储的不是上一个元素的长度，是当前元素的长度。正是因为长度放在了尾部，所以可以省去了zltail_offset字段来标记最后一个元素的位置，这个位置可以通过total_bytes字段和最后一个元素的长度字段计算出来。长度字段使用 varint 进行编码，不同于 skiplist 元素长度的编码为 1 个字节或者 5 个字节，listpack 元素长度的编码可以是 1、2、3、4、5 个字节。同 UTF8 编码一样，它通过字节的最高为是否为 1 来决定编码的长度。同样，Redis 为了让 listpack 元素支持很多类型，它对 encoding 字段也进行了较为复杂的设计。0xxxxxxx 表示非负小整数，可以表示0~127。10xxxxxx 表示小字符串，长度范围是0~63，content字段为字符串的内容。110xxxxx yyyyyyyy 表示有符号整数，范围是-2048~2047。1110xxxx yyyyyyyy 表示中等长度的字符串，长度范围是0~4095，content字段为字符串的内容。11110000 aaaaaaaa bbbbbbbb cccccccc dddddddd 表示大字符串，四个字节表示长度，content字段为字符串内容。11110001 aaaaaaaa bbbbbbbb 表示 2 字节有符号整数。11110010 aaaaaaaa bbbbbbbb cccccccc 表示 3 字节有符号整数。11110011 aaaaaaaa bbbbbbbb cccccccc dddddddd 表示 4 字节有符号整数。11110011 aaaaaaaa … hhhhhhhh 表示 8 字节有符号整数。11111111 表示 listpack 的结束符号，也就是0xFF。2. 级联更新listpack 的设计彻底消灭了 ziplist 存在的级联更新行为，元素与元素之间完全独立，不会因为一个元素的长度变长就导致后续的元素内容会受到影响。3. 取代 ziplistlistpack 的设计的目的是用来取代 ziplist，不过当下还没有做好替换 ziplist 的准备，因为有很多兼容性的问题需要考虑，ziplist 在 Redis 数据结构中使用太广泛了，替换起来复杂度会非常之高。它目前只使用在了新增加的 Stream 数据结构中。","categories":[{"name":"Redis","slug":"Redis","permalink":"http://localhost:4000/categories/Redis/"},{"name":"源码","slug":"Redis/源码","permalink":"http://localhost:4000/categories/Redis/源码/"}],"tags":[]},{"title":"Redis 跳跃列表结构","slug":"Redis-跳跃列表结构","date":"2019-06-19T14:29:39.000Z","updated":"2019-06-19T15:30:38.727Z","comments":true,"path":"2019/06/19/Redis-跳跃列表结构/","link":"","permalink":"http://localhost:4000/2019/06/19/Redis-跳跃列表结构/","excerpt":"","text":"Redis 深度历险：核心原理与应用实践 - 老錢 - 掘金小册Redis 跳跃列表结构1. 简介Redis 的 zset 是一个复合结构，一方面它需要一个 hash 结构来存储 value 和 score 的对应关系，另一方面需要提供按照 score 来排序的功能，还需要能够指定 score 的范围来获取 value 列表的功能，这就需要另外一个结构「跳跃列表」。zset 的内部实现是一个 hash 字典加一个跳跃列表 (skiplist)。hash 结构在讲字典结构时已经详细分析过了，它很类似于 Java 语言中的 HashMap 结构。本节我们来讲跳跃列表，它比较复杂，读者要有心理准备。2. 基本结构上图就是跳跃列表的示意图，图中只画了四层，Redis 的跳跃表共有 64 层，意味着最多可以容纳 2^64 次方个元素。每一个 kv 块对应的结构如下面的代码中的zslnode结构，kv header 也是这个结构，只不过 value 字段是 null 值——无效的，score 是 Double.MIN_VALUE，用来垫底的。kv 之间使用指针串起来形成了双向链表结构，它们是 有序 排列的，从小到大。不同的 kv 层高可能不一样，层数越高的 kv 越少。同一层的 kv 会使用指针串起来。每一个层元素的遍历都是从 kv header 出发。123456789101112struct zslnode &#123;string value;double score;zslnode*[] forwards; // 多层连接指针zslnode* backward; // 回溯指针&#125;struct zsl &#123;zslnode* header; // 跳跃列表头指针int maxLevel; // 跳跃列表当前的最高层map&lt;string, zslnode*&gt; ht; // hash 结构的所有键值对&#125;3. 查找过程设想如果跳跃列表只有一层会怎样？插入删除操作需要定位到相应的位置节点 (定位到最后一个比「我」小的元素，也就是第一个比「我」大的元素的前一个)，定位的效率肯定比较差，复杂度将会是 O(n)，因为需要挨个遍历。也许你会想到二分查找，但是二分查找的结构只能是有序数组。跳跃列表有了多层结构之后，这个定位的算法复杂度将会降到 O(lg(n))。如图所示，我们要定位到那个紫色的 kv，需要从 header 的最高层开始遍历找到第一个节点 (最后一个比「我」小的元素)，然后从这个节点开始降一层再遍历找到第二个节点 (最后一个比「我」小的元素)，然后一直降到最底层进行遍历就找到了期望的节点 (最底层的最后一个比我「小」的元素)。我们将中间经过的一系列节点称之为「搜索路径」，它是从最高层一直到最底层的每一层最后一个比「我」小的元素节点列表。有了这个搜索路径，我们就可以插入这个新节点了。不过这个插入过程也不是特别简单。因为新插入的节点到底有多少层，得有个算法来分配一下，跳跃列表使用的是随机算法。4. 随机层数对于每一个新插入的节点，都需要调用一个随机算法给它分配一个合理的层数。直观上期望的目标是 50% 的 Level1，25% 的 Level2，12.5% 的 Level3，一直到最顶层2^-63，因为这里每一层的晋升概率是 50%。12345678910/* Returns a random level for the new skiplist node we are going to create.* The return value of this function is between 1 and ZSKIPLIST_MAXLEVEL* (both inclusive), with a powerlaw-alike distribution where higher* levels are less likely to be returned. */int zslRandomLevel(void) &#123;int level = 1;while ((random()&amp;0xFFFF) &lt; (ZSKIPLIST_P * 0xFFFF))level += 1;return (level&lt;ZSKIPLIST_MAXLEVEL) ? level : ZSKIPLIST_MAXLEVEL;&#125;不过 Redis 标准源码中的晋升概率只有 25%，也就是代码中的 ZSKIPLIST_P 的值。所以官方的跳跃列表更加的扁平化，层高相对较低，在单个层上需要遍历的节点数量会稍多一点。也正是因为层数一般不高，所以遍历的时候从顶层开始往下遍历会非常浪费。跳跃列表会记录一下当前的最高层数maxLevel，遍历时从这个 maxLevel 开始遍历性能就会提高很多。5. 插入过程下面是插入过程的源码，它稍微有点长，不过整体的过程还是比较清晰的。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869/* Insert a new node in the skiplist. Assumes the element does not already* exist (up to the caller to enforce that). The skiplist takes ownership* of the passed SDS string 'ele'. */zskiplistNode *zslInsert(zskiplist *zsl, double score, sds ele) &#123;// 存储搜索路径zskiplistNode *update[ZSKIPLIST_MAXLEVEL], *x;// 存储经过的节点跨度unsigned int rank[ZSKIPLIST_MAXLEVEL];int i, level;serverAssert(!isnan(score));x = zsl-&gt;header;// 逐步降级寻找目标节点，得到「搜索路径」for (i = zsl-&gt;level-1; i &gt;= 0; i--) &#123;/* store rank that is crossed to reach the insert position */rank[i] = i == (zsl-&gt;level-1) ? 0 : rank[i+1];// 如果score相等，还需要比较valuewhile (x-&gt;level[i].forward &amp;&amp;(x-&gt;level[i].forward-&gt;score &lt; score ||(x-&gt;level[i].forward-&gt;score == score &amp;&amp;sdscmp(x-&gt;level[i].forward-&gt;ele,ele) &lt; 0)))&#123;rank[i] += x-&gt;level[i].span;x = x-&gt;level[i].forward;&#125;update[i] = x;&#125;// 正式进入插入过程/* we assume the element is not already inside, since we allow duplicated* scores, reinserting the same element should never happen since the* caller of zslInsert() should test in the hash table if the element is* already inside or not. */// 随机一个层数level = zslRandomLevel();// 填充跨度if (level &gt; zsl-&gt;level) &#123;for (i = zsl-&gt;level; i &lt; level; i++) &#123;rank[i] = 0;update[i] = zsl-&gt;header;update[i]-&gt;level[i].span = zsl-&gt;length;&#125;// 更新跳跃列表的层高zsl-&gt;level = level;&#125;// 创建新节点x = zslCreateNode(level,score,ele);// 重排一下前向指针for (i = 0; i &lt; level; i++) &#123;x-&gt;level[i].forward = update[i]-&gt;level[i].forward;update[i]-&gt;level[i].forward = x;/* update span covered by update[i] as x is inserted here */x-&gt;level[i].span = update[i]-&gt;level[i].span - (rank[0] - rank[i]);update[i]-&gt;level[i].span = (rank[0] - rank[i]) + 1;&#125;/* increment span for untouched levels */for (i = level; i &lt; zsl-&gt;level; i++) &#123;update[i]-&gt;level[i].span++;&#125;// 重排一下后向指针x-&gt;backward = (update[0] == zsl-&gt;header) ? NULL : update[0];if (x-&gt;level[0].forward)x-&gt;level[0].forward-&gt;backward = x;elsezsl-&gt;tail = x;zsl-&gt;length++;return x;&#125;首先我们在搜索合适插入点的过程中将「搜索路径」摸出来了，然后就可以开始创建新节点了，创建的时候需要给这个节点随机分配一个层数，再将搜索路径上的节点和这个新节点通过前向后向指针串起来。如果分配的新节点的高度高于当前跳跃列表的最大高度，就需要更新一下跳跃列表的最大高度。6. 删除过程删除过程和插入过程类似，都需先把这个「搜索路径」找出来。然后对于每个层的相关节点都重排一下前向后向指针就可以了。同时还要注意更新一下最高层数maxLevel。7. 更新过程当我们调用 zadd 方法时，如果对应的 value 不存在，那就是插入过程。如果这个 value 已经存在了，只是调整一下 score 的值，那就需要走一个更新的流程。假设这个新的 score 值不会带来排序位置上的改变，那么就不需要调整位置，直接修改元素的 score 值就可以了。但是如果排序位置改变了，那就要调整位置。那该如何调整位置呢？12345678910111213141516/* Remove and re-insert when score changes. */if (score != curscore) &#123;zskiplistNode *node;serverAssert(zslDelete(zs-&gt;zsl,curscore,ele,&amp;node));znode = zslInsert(zs-&gt;zsl,score,node-&gt;ele);/* We reused the node-&gt;ele SDS string, free the node now* since zslInsert created a new one. */node-&gt;ele = NULL;zslFreeNode(node);/* Note that we did not removed the original element from* the hash table representing the sorted set, so we just* update the score. */dictGetVal(de) = &amp;znode-&gt;score; /* Update score ptr. */*flags |= ZADD_UPDATED;&#125;return 1;一个简单的策略就是先删除这个元素，再插入这个元素，需要经过两次路径搜索。Redis 就是这么干的。 不过 Redis 遇到 score 值改变了就直接删除再插入，不会去判断位置是否需要调整，从这点看，Redis 的 zadd 的代码似乎还有优化空间。关于这一点，读者们可以继续讨论。8. 如果 score 值都一样呢？在一个极端的情况下，zset 中所有的 score 值都是一样的，zset 的查找性能会退化为 O(n) 么？Redis 作者自然考虑到了这一点，所以 zset 的排序元素不只看 score 值，如果 score 值相同还需要再比较 value 值 (字符串比较)。9. 元素排名是怎么算出来的？前面我们啰嗦了一堆，但是有一个重要的属性没有提到，那就是 zset 可以获取元素的排名 rank。那这个 rank 是如何算出来的？如果仅仅使用上面的结构，rank 是不能算出来的。Redis 在 skiplist 的 forward 指针上进行了优化，给每一个 forward 指针都增加了 span 属性，span 是「跨度」的意思，表示从前一个节点沿着当前层的 forward 指针跳到当前这个节点中间会跳过多少个节点。Redis 在插入删除操作时会小心翼翼地更新 span 值的大小。1234567891011struct zslforward &#123;zslnode* item;long span; // 跨度&#125;struct zsl &#123;String value;double score;zslforward*[] forwards; // 多层连接指针zslnode* backward; // 回溯指针&#125;这样当我们要计算一个元素的排名时，只需要将「搜索路径」上的经过的所有节点的跨度 span 值进行叠加就可以算出元素的最终 rank 值。","categories":[{"name":"Redis","slug":"Redis","permalink":"http://localhost:4000/categories/Redis/"},{"name":"源码","slug":"Redis/源码","permalink":"http://localhost:4000/categories/Redis/源码/"}],"tags":[]},{"title":"Redis 快速列表结构","slug":"Redis-快速列表结构","date":"2019-06-19T14:24:06.000Z","updated":"2019-06-19T15:30:46.945Z","comments":true,"path":"2019/06/19/Redis-快速列表结构/","link":"","permalink":"http://localhost:4000/2019/06/19/Redis-快速列表结构/","excerpt":"","text":"Redis 快速列表结构1. 简介Redis 早期版本存储 list 列表数据结构使用的是压缩列表 ziplist 和普通的双向链表 linkedlist，也就是元素少时用 ziplist，元素多时用 linkedlist。123456789101112// 链表的节点struct listNode&lt;T&gt; &#123;listNode* prev;listNode* next;T value;&#125;// 链表struct list &#123;listNode *head;listNode *tail;long length;&#125;考虑到链表的附加空间相对太高，prev 和 next 指针就要占去 16 个字节 (64bit 系统的指针是 8 个字节)，另外每个节点的内存都是单独分配，会加剧内存的碎片化，影响内存管理效率。后续版本对列表数据结构进行了改造，使用 quicklist 代替了 ziplist 和 linkedlist。1234&gt; rpush codehole go java python(integer) 3&gt; debug object codeholeValue at:0x7fec2dc2bde0 refcount:1 encoding:quicklist serializedlength:31 lru:6101643 lru_seconds_idle:5 ql_nodes:1 ql_avg_node:3.00 ql_ziplist_max:-2 ql_compressed:0 ql_uncompressed_size:29注意观察上面输出字段 encoding 的值。quicklist 是 ziplist 和 linkedlist 的混合体，它将 linkedlist 按段切分，每一段使用 ziplist 来紧凑存储，多个 ziplist 之间使用双向指针串接起来。123456789101112131415161718192021222324struct ziplist &#123;...&#125;struct ziplist_compressed &#123;int32 size;byte[] compressed_data;&#125;struct quicklistNode &#123;quicklistNode* prev;quicklistNode* next;ziplist* zl; // 指向压缩列表int32 size; // ziplist 的字节总数int16 count; // ziplist 中的元素数量int2 encoding; // 存储形式 2bit，原生字节数组还是 LZF 压缩存储...&#125;struct quicklist &#123;quicklistNode* head;quicklistNode* tail;long count; // 元素总数int nodes; // ziplist 节点的个数int compressDepth; // LZF 算法压缩深度...&#125;icklist 的大致结构。为了进一步节约空间，Redis 还会对 ziplist 进行压缩存储，使用 LZF 算法压缩，可以选择压缩深度。2. 每个 ziplist 存多少元素？quicklist 内部默认单个 ziplist 长度为 8k 字节，超出了这个字节数，就会新起一个 ziplist。ziplist 的长度由配置参数list-max-ziplist-size决定。1234567891011121314# Lists are also encoded in a special way to save a lot of space.# The number of entries allowed per internal list node can be specified# as a fixed maximum size or a maximum number of elements.# For a fixed maximum size, use -5 through -1, meaning:# -5: max size: 64 Kb &lt;-- not recommended for normal workloads# -4: max size: 32 Kb &lt;-- not recommended# -3: max size: 16 Kb &lt;-- probably not recommended# -2: max size: 8 Kb &lt;-- good# -1: max size: 4 Kb &lt;-- good# Positive numbers mean store up to _exactly_ that number of elements# per list node.# The highest performing option is usually -2 (8 Kb size) or -1 (4 Kb size),# but if your use case is unique, adjust the settings as necessary.list-max-ziplist-size -23. 压缩深度quicklist 默认的压缩深度是 0，也就是不压缩。压缩的实际深度由配置参数list-compress-depth决定。为了支持快速的 push/pop 操作，quicklist 的首尾两个 ziplist 不压缩，此时深度就是 1。如果深度为 2，就表示 quicklist 的首尾第一个 ziplist 以及首尾第二个 ziplist 都不压缩。","categories":[{"name":"Redis","slug":"Redis","permalink":"http://localhost:4000/categories/Redis/"},{"name":"源码","slug":"Redis/源码","permalink":"http://localhost:4000/categories/Redis/源码/"}],"tags":[]},{"title":"Redis 压缩列表结构","slug":"Redis-压缩列表结构","date":"2019-06-19T13:24:54.000Z","updated":"2019-06-19T15:26:00.641Z","comments":true,"path":"2019/06/19/Redis-压缩列表结构/","link":"","permalink":"http://localhost:4000/2019/06/19/Redis-压缩列表结构/","excerpt":"","text":"Redis 压缩列表结构1.简介Redis 为了节约内存空间使用，zset 和 hash 容器对象在元素个数较少的时候，采用压缩列表 (ziplist) 进行存储。压缩列表是一块连续的内存空间，元素之间紧挨着存储，没有任何冗余空隙。12345678&gt; zadd programmings 1.0 go 2.0 python 3.0 java(integer) 3&gt; debug object programmingsValue at:0x7fec2de00020 refcount:1 encoding:ziplist serializedlength:36 lru:6022374 lru_seconds_idle:6&gt; hmset books go fast python slow java fastOK&gt; debug object booksValue at:0x7fec2de000c0 refcount:1 encoding:ziplist serializedlength:48 lru:6022478 lru_seconds_idle:1这里，注意观察 debug object 输出的 encoding 字段都是 ziplist，这就表示内部采用压缩列表结构进行存储。1234567struct ziplist&lt;T&gt; &#123;int32 zlbytes; // 整个压缩列表占用字节数int32 zltail_offset; // 最后一个元素距离压缩列表起始位置的偏移量，用于快速定位到最后一个节点int16 zllength; // 元素个数T[] entries; // 元素内容列表，挨个挨个紧凑存储int8 zlend; // 标志压缩列表的结束，值恒为 0xFF&#125;压缩列表为了支持双向遍历，所以才会有 ztail_offset 这个字段，用来快速定位到最后一个元素，然后倒着遍历。entry 块随着容纳的元素类型不同，也会有不一样的结构。12345struct entry &#123;int&lt;var&gt; prevlen; // 前一个 entry 的字节长度int&lt;var&gt; encoding; // 元素类型编码optional byte[] content; // 元素内容&#125;它的 prevlen 字段表示前一个 entry 的字节长度，当压缩列表倒着遍历时，需要通过这个字段来快速定位到下一个元素的位置。它是一个变长的整数，当字符串长度小于 254(0xFE) 时，使用一个字节表示；如果达到或超出 254(0xFE) 那就使用 5 个字节来表示。第一个字节是 0xFE(254)，剩余四个字节表示字符串长度。你可能会觉得用 5 个字节来表示字符串长度，是不是太浪费了。我们可以算一下，当字符串长度比较长的时候，其实 5 个字节也只占用了不到(5/(254+5))&lt;2%的空间。encoding字段存储了元素内容的编码类型信息，ziplist 通过这个字段来决定后面的 content 内容的形式。Redis 为了节约存储空间，对 encoding 字段进行了相当复杂的设计。Redis 通过这个字段的前缀位来识别具体存储的数据形式。下面我们来看看 Redis 是如何根据encoding的前缀位来区分内容的：00xxxxxx 最大长度位 63 的短字符串，后面的 6 个位存储字符串的位数，剩余的字节就是字符串的内容。01xxxxxx xxxxxxxx 中等长度的字符串，后面 14 个位来表示字符串的长度，剩余的字节就是字符串的内容。10000000 aaaaaaaa bbbbbbbb cccccccc dddddddd 特大字符串，需要使用额外 4 个字节来表示长度。第一个字节前缀是10，剩余 6 位没有使用，统一置为零。后面跟着字符串内容。不过这样的大字符串是没有机会使用的，压缩列表通常只是用来存储小数据的。11000000 表示 int16，后跟两个字节表示整数。11010000 表示 int32，后跟四个字节表示整数。11100000 表示 int64，后跟六个字节表示整数。11110000 表示 int24，后跟三个字节表示整数。11111110 表示 int8，后跟一个字节表示整数。11111111 表示 ziplist 的结束，也就是 zlend 的值 0xFF。1111xxxx 表示极小整数，xxxx 的范围只能是 (00011101), 也就是113，因为0000、1110、1111都被占用了。读取到的 value 需要将 xxxx 减 1，也就是整数0~12就是最终的 value。注意到 content 字段在结构体中定义为 optional 类型，表示这个字段是可选的，对于很小的整数而言，它的内容已经内联到 encoding 字段的尾部了。2.增加元素因为 ziplist 都是紧凑存储，没有冗余空间 (对比一下 Redis 的字符串结构)。意味着插入一个新的元素就需要调用 realloc 扩展内存。取决于内存分配器算法和当前的 ziplist 内存大小，realloc 可能会重新分配新的内存空间，并将之前的内容一次性拷贝到新的地址，也可能在原有的地址上进行扩展，这时就不需要进行旧内容的内存拷贝。如果 ziplist 占据内存太大，重新分配内存和拷贝内存就会有很大的消耗。所以 ziplist 不适合存储大型字符串，存储的元素也不宜过多。3.级联更新123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175/* When an entry is inserted, we need to set the prevlen field of the next\\* entry to equal the length of the inserted entry. It can occur that this\\* length cannot be encoded in 1 byte and the next entry needs to be grow\\* a bit larger to hold the 5-byte encoded prevlen. This can be done for free,\\* because this only happens when an entry is already being inserted (which\\* causes a realloc and memmove). However, encoding the prevlen may require\\* that this entry is grown as well. This effect may cascade throughout\\* the ziplist when there are consecutive entries with a size close to\\* ZIP_BIG_PREVLEN, so we need to check that the prevlen can be encoded in\\* every consecutive entry.*\\* Note that this effect can also happen in reverse, where the bytes required\\* to encode the prevlen field can shrink. This effect is deliberately ignored,\\* because it can cause a \"flapping\" effect where a chain prevlen fields is\\* first grown and then shrunk again after consecutive inserts. Rather, the\\* field is allowed to stay larger than necessary, because a large prevlen\\* field implies the ziplist is holding large entries anyway.*\\* The pointer \"p\" points to the first entry that does NOT need to be\\* updated, i.e. consecutive fields MAY need an update. */**unsigned** **char** *__ziplistCascadeUpdate(**unsigned** **char** *zl, **unsigned** **char** *p) &#123;**size_t** curlen = intrev32ifbe(ZIPLIST_BYTES(zl)), rawlen, rawlensize;**size_t** offset, noffset, extra;**unsigned** **char** *np;zlentry cur, next;**while** (p[0] != ZIP_END) &#123;zipEntry(p, &amp;cur);rawlen = cur.headersize + cur.len;rawlensize = zipStorePrevEntryLength(NULL,rawlen);/* Abort if there is no next entry. */**if** (p[rawlen] == ZIP_END) **break**;zipEntry(p+rawlen, &amp;next);/* Abort when \"prevlen\" has not changed. */// prevlen 的长度没有变，中断级联更新**if** (next.prevrawlen == rawlen) **break**;**if** (next.prevrawlensize &lt; rawlensize) &#123;/* The \"prevlen\" field of \"next\" needs more bytes to hold\\* the raw length of \"cur\". */// 级联扩展offset = p-zl;extra = rawlensize-next.prevrawlensize;// 扩大内存zl = ziplistResize(zl,curlen+extra);p = zl+offset;/* Current pointer and offset for next element. */np = p+rawlen;noffset = np-zl;/* Update tail offset when next element is not the tail element. */// 更新 zltail_offset 指针**if** ((zl+intrev32ifbe(ZIPLIST_TAIL_OFFSET(zl))) != np) &#123;ZIPLIST_TAIL_OFFSET(zl) =intrev32ifbe(intrev32ifbe(ZIPLIST_TAIL_OFFSET(zl))+extra);&#125;/* Move the tail to the back. */// 移动内存memmove(np+rawlensize,np+next.prevrawlensize,curlen-noffset-next.prevrawlensize-1);zipStorePrevEntryLength(np,rawlen);/* Advance the cursor */p += rawlen;curlen += extra;&#125; **else** &#123;**if** (next.prevrawlensize &gt; rawlensize) &#123;/* This would result in shrinking, which we want to avoid.\\* So, set \"rawlen\" in the available bytes. */// 级联收缩，不过这里可以不用收缩了，因为 5 个字节也是可以存储 1 个字节的内容的// 虽然有点浪费，但是级联更新实在是太可怕了，所以浪费就浪费吧zipStorePrevEntryLengthLarge(p+rawlen,rawlen);&#125; **else** &#123;// 大小没变，改个长度值就完事了zipStorePrevEntryLength(p+rawlen,rawlen);&#125;/* Stop here, as the raw length of \"next\" has not changed. */**break**;&#125;&#125;**return** zl;&#125;前面提到每个 entry 都会有一个 prevlen 字段存储前一个 entry 的长度。如果内容小于 254 字节，prevlen 用 1 字节存储，否则就是 5 字节。这意味着如果某个 entry 经过了修改操作从 253 字节变成了 254 字节，那么它的下一个 entry 的 prevlen字段就要更新，从 1 个字节扩展到 5 个字节；如果这个 entry 的长度本来也是 253 字节，那么后面 entry 的 prevlen 字段还得继续更新。如果 ziplist 里面每个 entry 恰好都存储了 253 字节的内容，那么第一个 entry 内容的修改就会导致后续所有 entry 的级联更新，这就是一个比较耗费计算资源的操作。删除中间的某个节点也可能会导致级联更新，读者可以思考一下为什么？4.IntSet 小整数集合当 set 集合容纳的元素都是整数并且元素个数较小时，Redis 会使用 intset 来存储结合元素。intset 是紧凑的数组结构，同时支持 16 位、32 位和 64 位整数。struct intset{int32 encoding; // 决定整数位宽是 16 位、32 位还是 64 位int32 length; // 元素个数intcontents; // 整数数组，可以是 16 位、32 位和 64 位}毕竟它只是用来存储小整数的，长度不应该很长，而且 encoding 只有 16 位、32 位和 64 位三个类型，用一个字节存储就绰绰有余。关于这点，读者们可以进一步讨论。12345678&gt; sadd codehole 1 2 3(integer) 3&gt; debug object codeholeValue at:0x7fec2dc2bde0 refcount:1 encoding:intset serializedlength:15 lru:6065795 lru_seconds_idle:4&gt; sadd codehole go java python(integer) 3&gt; debug object codeholeValue at:0x7fec2dc2bde0 refcount:1 encoding:hashtable serializedlength:22 lru:6065810 lru_seconds_idle:5注意观察 debug object 的输出字段 encoding 的值，可以发现当 set 里面放进去了非整数值时，存储形式立即从 intset 转变成了 hash 结构。","categories":[{"name":"Redis","slug":"Redis","permalink":"http://localhost:4000/categories/Redis/"},{"name":"源码","slug":"Redis/源码","permalink":"http://localhost:4000/categories/Redis/源码/"}],"tags":[{"name":"redis","slug":"redis","permalink":"http://localhost:4000/tags/redis/"},{"name":"数据结构","slug":"数据结构","permalink":"http://localhost:4000/tags/数据结构/"}]},{"title":"Redis 字典结构","slug":"Redis-字典结构","date":"2019-06-19T13:16:10.000Z","updated":"2019-06-19T15:26:00.708Z","comments":true,"path":"2019/06/19/Redis-字典结构/","link":"","permalink":"http://localhost:4000/2019/06/19/Redis-字典结构/","excerpt":"","text":"Redis 字典结构1.简介dict 是 Redis 服务器中出现最为频繁的复合型数据结构，除了 hash 结构的数据会用到字典外，整个 Redis 数据库的所有 key 和 value 也组成了一个全局字典，还有带过期时间的 key 集合也是一个字典。zset 集合中存储 value 和 score 值的映射关系也是通过 dict 结构实现的。12345678910struct RedisDb &#123;dict* dict; // all keys key=&gt;valuedict* expires; // all expired keys key=&gt;long(timestamp)...&#125;struct zset &#123;dict *dict; // all values value=&gt;scorezskiplist *zsl;&#125;2.dict 内部结构dict 结构内部包含两个 hashtable，通常情况下只有一个 hashtable 是有值的。但是在 dict 扩容缩容时，需要分配新的 hashtable，然后进行渐进式搬迁，这时候两个 hashtable 存储的分别是旧的 hashtable 和新的 hashtable。待搬迁结束后，旧的 hashtable 被删除，新的 hashtable 取而代之。1234struct dict &#123;...dictht ht[2];&#125;所以，字典数据结构的精华就落在了 hashtable 结构上了。hashtable 的结构和 Java 的 HashMap 几乎是一样的，都是通过分桶的方式解决 hash 冲突。第一维是数组，第二维是链表。数组中存储的是第二维链表的第一个元素的指针。1234567891011struct dictEntry &#123;void* key;void* val;dictEntry* next; // 链接下一个 entry&#125;struct dictht &#123;dictEntry** table; // 二维long size; // 第一维数组的长度long used; // hash 表中的元素个数...&#125;3. 渐进式rehash大字典的扩容是比较耗时间的，需要重新申请新的数组，然后将旧字典所有链表中的元素重新挂接到新的数组下面，这是一个O(n)级别的操作，作为单线程的Redis表示很难承受这样耗时的过程。步子迈大了会扯着蛋，所以Redis使用渐进式rehash小步搬迁。虽然慢一点，但是肯定可以搬完。1234567891011121314151617181920212223242526272829dictEntry *dictAddRaw(dict *d, void *key, dictEntry **existing)&#123;long index;dictEntry *entry;dictht *ht;// 这里进行小步搬迁if (dictIsRehashing(d)) _dictRehashStep(d);/* Get the index of the new element, or -1 if* the element already exists. */if ((index = _dictKeyIndex(d, key, dictHashKey(d,key), existing)) == -1)return NULL;/* Allocate the memory and store the new entry.* Insert the element in top, with the assumption that in a database* system it is more likely that recently added entries are accessed* more frequently. */// 如果字典处于搬迁过程中，要将新的元素挂接到新的数组下面ht = dictIsRehashing(d) ? &amp;d-&gt;ht[1] : &amp;d-&gt;ht[0];entry = zmalloc(sizeof(*entry));entry-&gt;next = ht-&gt;table[index];ht-&gt;table[index] = entry;ht-&gt;used++;/* Set the hash entry fields. */dictSetKey(d, entry, key);return entry;&#125;搬迁操作埋伏在当前字典的后续指令中(来自客户端的hset/hdel指令等)，但是有可能客户端闲下来了，没有了后续指令来触发这个搬迁，那么Redis就置之不理了么？当然不会，优雅的Redis怎么可能设计的这样潦草。Redis还会在定时任务中对字典进行主动搬迁。123456789101112131415161718// 服务器定时任务void databaseCron() &#123;...if (server.activerehashing) &#123;for (j = 0; j &lt; dbs_per_call; j++) &#123;int work_done = incrementallyRehash(rehash_db);if (work_done) &#123;/* If the function did some work, stop here, we'll do* more at the next cron loop. */break;&#125; else &#123;/* If this db didn't need rehash, we'll try the next one. */rehash_db++;rehash_db %= server.dbnum;&#125;&#125;&#125;&#125;4.查找过程插入和删除操作都依赖于查找，先必须把元素找到，才可以进行数据结构的修改操作。hashtable 的元素是在第二维的链表上，所以首先我们得想办法定位出元素在哪个链表上。12345678910func get(key) &#123;let index = hash_func(key) % size;let entry = table[index];while(entry != NULL) &#123;if entry.key == target &#123;return entry.value;&#125;entry = entry.next;&#125;&#125;值得注意的是代码中的hash_func，它会将 key 映射为一个整数，不同的 key 会被映射成分布比较均匀散乱的整数。只有 hash 值均匀了，整个 hashtable 才是平衡的，所有的二维链表的长度就不会差距很远，查找算法的性能也就比较稳定。5. hash 函数hashtable 的性能好不好完全取决于 hash 函数的质量。hash 函数如果可以将 key 打散的比较均匀，那么这个 hash 函数就是个好函数。Redis 的字典默认的 hash 函数是 siphash。siphash 算法即使在输入 key 很小的情况下，也可以产生随机性特别好的输出，而且它的性能也非常突出。对于 Redis 这样的单线程来说，字典数据结构如此普遍，字典操作也会非常频繁，hash 函数自然也是越快越好。6.hash 攻击如果 hash 函数存在偏向性，黑客就可能利用这种偏向性对服务器进行攻击。存在偏向性的 hash 函数在特定模式下的输入会导致 hash 第二维链表长度极为不均匀，甚至所有的元素都集中到个别链表中，直接导致查找效率急剧下降，从O(1)退化到O(n)。有限的服务器计算能力将会被 hashtable 的查找效率彻底拖垮。这就是所谓 hash 攻击。7.扩容条件123456789101112131415161718192021/* Expand the hash table if needed */static int _dictExpandIfNeeded(dict *d)&#123;/* Incremental rehashing already in progress. Return. */if (dictIsRehashing(d)) return DICT_OK;/* If the hash table is empty expand it to the initial size. */if (d-&gt;ht[0].size == 0) return dictExpand(d, DICT_HT_INITIAL_SIZE);/* If we reached the 1:1 ratio, and we are allowed to resize the hash* table (global setting) or we should avoid it but the ratio between* elements/buckets is over the \"safe\" threshold, we resize doubling* the number of buckets. */if (d-&gt;ht[0].used &gt;= d-&gt;ht[0].size &amp;&amp;(dict_can_resize ||d-&gt;ht[0].used/d-&gt;ht[0].size &gt; dict_force_resize_ratio))&#123;return dictExpand(d, d-&gt;ht[0].used*2);&#125;return DICT_OK;&#125;正常情况下，当 hash 表中元素的个数等于第一维数组的长度时，就会开始扩容，扩容的新数组是原数组大小的 2 倍。不过如果 Redis 正在做 bgsave，为了减少内存页的过多分离 (Copy On Write)，Redis 尽量不去扩容 (dict_can_resize)，但是如果 hash 表已经非常满了，元素的个数已经达到了第一维数组长度的 5 倍 (dict_force_resize_ratio)，说明 hash 表已经过于拥挤了，这个时候就会强制扩容。8.缩容条件12345678int htNeedsResize(dict *dict) &#123;long long size, used;size = dictSlots(dict);used = dictSize(dict);return (size &gt; DICT_HT_INITIAL_SIZE &amp;&amp;(used*100/size &lt; HASHTABLE_MIN_FILL));&#125;当 hash 表因为元素的逐渐删除变得越来越稀疏时，Redis 会对 hash 表进行缩容来减少 hash 表的第一维数组空间占用。缩容的条件是元素个数低于数组长度的 10%。缩容不会考虑 Redis 是否正在做 bgsave。9.set 的结构Redis 里面 set 的结构底层实现也是字典，只不过所有的 value 都是 NULL，其它的特性和字典一模一样。","categories":[{"name":"Redis","slug":"Redis","permalink":"http://localhost:4000/categories/Redis/"},{"name":"源码","slug":"Redis/源码","permalink":"http://localhost:4000/categories/Redis/源码/"}],"tags":[{"name":"redis","slug":"redis","permalink":"http://localhost:4000/tags/redis/"},{"name":"数据结构","slug":"数据结构","permalink":"http://localhost:4000/tags/数据结构/"},{"name":"字典","slug":"字典","permalink":"http://localhost:4000/tags/字典/"}]},{"title":"Redis 字符串结构","slug":"Redis-字符串结构","date":"2019-06-19T13:11:22.000Z","updated":"2019-06-19T15:59:18.699Z","comments":true,"path":"2019/06/19/Redis-字符串结构/","link":"","permalink":"http://localhost:4000/2019/06/19/Redis-字符串结构/","excerpt":"","text":"Redis 字符串结构1.简介redis 中的字符串是可以修改的字符串，在内存中它是以字节数组的形式存在的。我们知道 C 语言里面的字符串标准形式是以 NULL 作为结束符，但是在 Redis 里面字符串不是这么表示的。因为要获取 NULL 结尾的字符串的长度使用的是 strlen 标准库函数，这个函数的算法复杂度是 O(n)，它需要对字节数组进行遍历扫描，作为单线程的 Redis 表示承受不起。redis 中的字符串是可以修改的字符串，在内存中它是以字节数组的形式存在的。我们知道 C 语言里面的字符串标准形式是以 NULL 作为结束符，但是在 Redis 里面字符串不是这么表示的。因为要获取 NULL 结尾的字符串的长度使用的是 strlen 标准库函数，这个函数的算法复杂度是 O(n)，它需要对字节数组进行遍历扫描，作为单线程的 Redis 表示承受不起。2.内部结构Redis 的字符串叫着「SDS」，也就是Simple Dynamic String。它的结构是一个带长度信息的字节数组。123456struct SDS&lt;T&gt; &#123;T capacity; // 数组容量T len; // 数组长度byte flags; // 特殊标识位，不理睬它byte[] content; // 数组内容&#125;如代码所示，content 里面存储了真正的字符串内容，那 capacity 和 len 表示什么意思呢？它有点类似于 Java 语言的 ArrayList 结构，需要比实际的内容长度多分配一些冗余空间。capacity 表示所分配数组的长度，len 表示字符串的实际长度。前面我们提到字符串是可以修改的字符串，它要支持 append 操作。如果数组没有冗余空间，那么追加操作必然涉及到分配新数组，然后将旧内容复制过来，再 append 新内容。如果字符串的长度非常长，这样的内存分配和复制开销就会非常大。12345678910111213141516/* Append the specified binary-safe string pointed by 't' of 'len' bytes to the* end of the specified sds string 's'.** After the call, the passed sds string is no longer valid and all the* references must be substituted with the new pointer returned by the call. */sds sdscatlen(sds s, const void *t, size_t len) &#123;size_t curlen = sdslen(s); // 原字符串长度// 按需调整空间，如果 capacity 不够容纳追加的内容，就会重新分配字节数组并复制原字符串的内容到新数组中s = sdsMakeRoomFor(s,len);if (s == NULL) return NULL; // 内存不足memcpy(s+curlen, t, len); // 追加目标字符串的内容到字节数组中sdssetlen(s, curlen+len); // 设置追加后的长度值s[curlen+len] = '\\0'; // 让字符串以\\0 结尾，便于调试打印，还可以直接使用 glibc 的字符串函数进行操作return s;&#125;上面的 SDS 结构使用了范型 T，为什么不直接用 int 呢，这是因为当字符串比较短时，len 和 capacity 可以使用 byte 和 short 来表示，Redis 为了对内存做极致的优化，不同长度的字符串使用不同的结构体来表示。Redis 规定字符串的长度不得超过 512M 字节。创建字符串时 len 和 capacity 一样长，不会多分配冗余空间，这是因为绝大多数场景下我们不会使用 append 操作来修改字符串。3.存储方式Redis 的字符串有两种存储方式，在长度特别短时，使用 emb 形式存储 (embeded)，当长度超过 44 时，使用 raw 形式存储。这两种类型有什么区别呢？为什么分界线是 44 呢？12345678&gt; set codehole abcdefghijklmnopqrstuvwxyz012345678912345678OK&gt; debug object codeholeValue at:0x7fec2de00370 refcount:1 encoding:embstr serializedlength:45 lru:5958906 lru_seconds_idle:1&gt; set codehole abcdefghijklmnopqrstuvwxyz0123456789123456789OK&gt; debug object codeholeValue at:0x7fec2dd0b750 refcount:1 encoding:raw serializedlength:46 lru:5958911 lru_seconds_idle:1注意上面 debug object 输出中有个 encoding 字段，一个字符的差别，存储形式就发生了变化。这是为什么呢？为了解释这种现象，我们首先来了解一下 Redis 对象头结构体，所有的 Redis 对象都有下面的这个结构头:1234567struct RedisObject &#123;int4 type; // 4bitsint4 encoding; // 4bitsint24 lru; // 24bitsint32 refcount; // 4bytesvoid *ptr; // 8bytes，64-bit system&#125; robj;不同的对象具有不同的类型 type(4bit)，同一个类型的 type 会有不同的存储形式 encoding(4bit)，为了记录对象的 LRU 信息，使用了 24 个 bit 来记录 LRU 信息。每个对象都有个引用计数，当引用计数为零时，对象就会被销毁，内存被回收。ptr指针将指向对象内容 (body) 的具体存储位置。这样一个 RedisObject 对象头需要占据 16 字节的存储空间。接着我们再看 SDS 结构体的大小，在字符串比较小时，SDS 对象头的大小是capacity+3，至少是 3。意味着分配一个字符串的最小空间占用为 19 字节 (16+3)。123456struct SDS &#123;int8 capacity; // 1byteint8 len; // 1byteint8 flags; // 1bytebyte[] content; // 内联数组，长度为 capacity&#125;如图所示，embstr 存储形式是这样一种存储形式，它将 RedisObject 对象头和 SDS 对象连续存在一起，使用 malloc 方法一次分配。而 raw 存储形式不一样，它需要两次 malloc，两个对象头在内存地址上一般是不连续的。而内存分配器 jemalloc/tcmalloc 等分配内存大小的单位都是 2、4、8、16、32、64 等等，为了能容纳一个完整的 embstr 对象，jemalloc 最少会分配 32 字节的空间，如果字符串再稍微长一点，那就是 64 字节的空间。如果总体超出了 64 字节，Redis 认为它是一个大字符串，不再使用 emdstr 形式存储，而该用 raw 形式。当内存分配器分配了 64 空间时，那这个字符串的长度最大可以是多少呢？这个长度就是 44。那为什么是 44 呢？前面我们提到 SDS 结构体中的 content 中的字符串是以字节\\0结尾的字符串，之所以多出这样一个字节，是为了便于直接使用 glibc 的字符串处理函数，以及为了便于字符串的调试打印输出。看上面这张图可以算出，留给 content 的长度最多只有 45(64-19) 字节了。字符串又是以\\0结尾，所以 embstr 最大能容纳的字符串长度就是 44。4.扩容策略字符串在长度小于 1M 之前，扩容空间采用加倍策略，也就是保留 100% 的冗余空间。当长度超过 1M 之后，为了避免加倍后的冗余空间过大而导致浪费，每次扩容只会多分配 1M 大小的冗余空间。","categories":[{"name":"Redis","slug":"Redis","permalink":"http://localhost:4000/categories/Redis/"},{"name":"源码","slug":"Redis/源码","permalink":"http://localhost:4000/categories/Redis/源码/"}],"tags":[{"name":"redis","slug":"redis","permalink":"http://localhost:4000/tags/redis/"},{"name":"数据结构","slug":"数据结构","permalink":"http://localhost:4000/tags/数据结构/"}]},{"title":"Redis 源码内部结构综述","slug":"Redis-源码内部结构综述","date":"2019-06-18T14:03:31.000Z","updated":"2019-06-19T15:54:38.888Z","comments":true,"path":"2019/06/18/Redis-源码内部结构综述/","link":"","permalink":"http://localhost:4000/2019/06/18/Redis-源码内部结构综述/","excerpt":"","text":"Redis 源码内部结构综述1.简介Redis 和其他很多key-value数据库的不同之处在于，Redis不仅支持简单的字符串键值对，它还提供了一系列数据结构类型值，比如列表、哈希、集合和有序集，并在这些数据结构类型上定义了一套强大的API 。在Redis的内部，数据结构类型值由高效的数据结构和算法进行支持，并且在Redis 自身的构建当中，也大量用到了这些数据结构。主要有字符串、字典、压缩列表、快速列表、跳跃表、紧凑列表和基数树。2.内部结构具体分析系列文章列表Redis 字符串结构Redis 字典结构Redis 快速列表结构Redis 压缩列表结构Redis 跳跃列表结构Redis 紧凑列表结构Redis 基数树","categories":[{"name":"Redis","slug":"Redis","permalink":"http://localhost:4000/categories/Redis/"},{"name":"源码","slug":"Redis/源码","permalink":"http://localhost:4000/categories/Redis/源码/"}],"tags":[{"name":"redis","slug":"redis","permalink":"http://localhost:4000/tags/redis/"},{"name":"源码","slug":"源码","permalink":"http://localhost:4000/tags/源码/"}]},{"title":"Redis 基础数据结构","slug":"Redis-基础数据结构","date":"2019-06-17T14:58:23.000Z","updated":"2019-06-19T15:59:18.743Z","comments":true,"path":"2019/06/17/Redis-基础数据结构/","link":"","permalink":"http://localhost:4000/2019/06/17/Redis-基础数据结构/","excerpt":"","text":"Redis 基础数据结构1.安装体验 Redis 需要使用 Linux 或者 Mac 环境，如果是 Windows 可以考虑使用虚拟机。主要方式有四种：使用 Docker 安装。通过 Github 源码编译。直接安装 apt-get install(Ubuntu)、yum install(RedHat) 或者 brew install(Mac)。如果读者懒于安装操作，也可以使用网页版的 Web Redis 直接体验。2.基础数据结构Redis 有五种常用的数据类型，分别是string (字符串)、list (列表)、set (集合)、hash (哈希) 和 zset (有序集合)。一般我们也是经常使用这五种类型的数据，下面分别简述一下其中的内部结构是怎么样的。2.1 string (字符串)string是Redis中最为简单的数据结构，通过用Key-value的方式去存储、查找和更新。对于不同的数据，value的数据结构不同。字符串结构使用非常广泛，一个常见的用途就是缓存用户信息。我们将用户信息结构体使用 JSON 序列化成字符串，然后将序列化后的字符串塞进 Redis 来缓存。同样，取用户信息会经过一次反序列化的过程。Redis 的字符串是动态字符串，是可以修改的字符串，内部结构实现上类似于 Java 的 ArrayList，采用预分配冗余空间的方式来减少内存的频繁分配，如图中所示，内部为当前字符串实际分配的空间 capacity 一般要高于实际字符串长度 len。当字符串长度小于 1M 时，扩容都是加倍现有的空间，如果超过 1M，扩容时一次只会多扩 1M 的空间。需要注意的是字符串最大长度为 512M。在内存中是以字节数组的存储的。Redis 的字符串叫着「SDS」，也就是Simple Dynamic String。它的结构是一个带长度信息的字节数组。123456struct SDS&lt;T&gt; &#123;T capacity; // 数组容量T len; // 数组长度byte flags; // 特殊标识位，不理睬它byte[] content; // 数组内容&#125;参数分析：capacity是指数组的长度，一般会比实际的内容多分配一些空间len是实际的字符串的真是长度content是存储了真正的字符串的内容字符串是可以修改的字符串，它要支持 append 操作。如果数组没有冗余空间，那么追加操作必然涉及到分配新数组，然后将旧内容复制过来，再 append 新内容。如果字符串的长度非常长，这样的内存分配和复制开销就会非常大。12345678910111213141516/* Append the specified binary-safe string pointed by 't' of 'len' bytes to the* end of the specified sds string 's'.** After the call, the passed sds string is no longer valid and all the* references must be substituted with the new pointer returned by the call. */sds sdscatlen(sds s, const void *t, size_t len) &#123;size_t curlen = sdslen(s); // 原字符串长度// 按需调整空间，如果 capacity 不够容纳追加的内容，就会重新分配字节数组并复制原字符串的内容到新数组中s = sdsMakeRoomFor(s,len);if (s == NULL) return NULL; // 内存不足memcpy(s+curlen, t, len); // 追加目标字符串的内容到字节数组中sdssetlen(s, curlen+len); // 设置追加后的长度值s[curlen+len] = '\\0'; // 让字符串以\\0 结尾，便于调试打印，还可以直接使用 glibc 的字符串函数进行操作return s;&#125;上面的 SDS 结构使用了范型 T，为什么不直接用 int 呢，这是因为当字符串比较短时，len 和 capacity 可以使用 byte 和 short 来表示，Redis 为了对内存做极致的优化，不同长度的字符串使用不同的结构体来表示。Redis 规定字符串的长度不得超过 512M 字节。创建字符串时 len 和 capacity 一样长，不会多分配冗余空间，这是因为绝大多数场景下我们不会使用 append 操作来修改字符串。embstr vs rawRedis的两种存储字符串的方式。在长度特别短时，使用 emb 形式存储 (embeded)，当长度超过 44 时，使用 raw 形式存储。12345678127.0.0.1:6379&gt; set codehole abcdefghijklmnopqrstuvwxyz0123456789123456789OK127.0.0.1:6379&gt; debug object codeholeValue at:00007FD73D46E2D0 refcount:1 encoding:raw serializedlength:46 lru:505657 lru_seconds_idle:2127.0.0.1:6379&gt; set codehole abcdefghijOK127.0.0.1:6379&gt; debug object codeholeValue at:00007FD73D40A6A0 refcount:1 encoding:embstr serializedlength:11 lru:505690 lru_seconds_idle:2注意上面 debug object 输出中有个 encoding 字段，一个字符的差别，存储形式就发生了变化。这是为什么呢？我们首先来了解一下 Redis 对象头结构体，所有的 Redis 对象都有下面的这个结构头:1234567struct RedisObject &#123;int4 type; // 4bitsint4 encoding; // 4bitsint24 lru; // 24bitsint32 refcount; // 4bytesvoid *ptr; // 8bytes，64-bit system&#125; robj;不同的对象具有不同的类型 type(4bit)，同一个类型的 type 会有不同的存储形式 encoding(4bit)，为了记录对象的 LRU 信息，使用了 24 个 bit 来记录 LRU 信息。每个对象都有个引用计数，当引用计数为零时，对象就会被销毁，内存被回收。ptr指针将指向对象内容 (body) 的具体存储位置。这样一个 RedisObject 对象头需要占据 16 字节的存储空间。接着我们再看 SDS 结构体的大小，在字符串比较小时，SDS 对象头的大小是capacity+3，至少是 3。意味着分配一个字符串的最小空间占用为 19 字节 (16+3)。123456struct SDS &#123;int8 capacity; // 1byteint8 len; // 1byteint8 flags; // 1bytebyte[] content; // 内联数组，长度为 capacity&#125;如图所示，embstr 存储形式是这样一种存储形式，它将 RedisObject 对象头和 SDS 对象连续存在一起，使用 malloc 方法一次分配。而 raw 存储形式不一样，它需要两次 malloc，两个对象头在内存地址上一般是不连续的。而内存分配器 jemalloc/tcmalloc 等分配内存大小的单位都是 2、4、8、16、32、64 等等，为了能容纳一个完整的 embstr 对象，jemalloc 最少会分配 32 字节的空间，如果字符串再稍微长一点，那就是 64 字节的空间。如果总体超出了 64 字节，Redis 认为它是一个大字符串，不再使用 emdstr 形式存储，而该用 raw 形式。当内存分配器分配了 64 空间时，那这个字符串的长度最大可以是多少呢？这个长度就是 44。那为什么是 44 呢？前面我们提到 SDS 结构体中的 content 中的字符串是以字节\\0结尾的字符串，之所以多出这样一个字节，是为了便于直接使用 glibc 的字符串处理函数，以及为了便于字符串的调试打印输出。看上面这张图可以算出，留给 content 的长度最多只有 45(64-19) 字节了。字符串又是以\\0结尾，所以 embstr 最大能容纳的字符串长度就是 44。扩容策略字符串在长度小于 1M 之前，扩容空间采用加倍策略，也就是保留 100% 的冗余空间。当长度超过 1M 之后，为了避免加倍后的冗余空间过大而导致浪费，每次扩容只会多分配 1M 大小的冗余空间。指令键值对12345678910&gt; set name codeholeOK&gt; get name&quot;codehole&quot;&gt; exists name(integer) 1&gt; del name(integer) 1&gt; get name(nil)批量键值对12345678910111213&gt; set name1 codeholeOK&gt; set name2 holycoderOK&gt; mget name1 name2 name3 # 返回一个列表1) &quot;codehole&quot;2) &quot;holycoder&quot;3) (nil)&gt; mset name1 boy name2 girl name3 unknown&gt; mget name1 name2 name31) &quot;boy&quot;2) &quot;girl&quot;3) &quot;unknown&quot;过期和 set 命令扩展1234567891011121314151617181920212223&gt; set name codehole&gt; get name&quot;codehole&quot;&gt; expire name 5 # 5s 后过期... # wait for 5s&gt; get name(nil)&gt; setex name 5 codehole # 5s 后过期，等价于 set+expire&gt; get name&quot;codehole&quot;... # wait for 5s&gt; get name(nil)&gt; setnx name codehole # 如果 name 不存在就执行 set 创建(integer) 1&gt; get name&quot;codehole&quot;&gt; setnx name holycoder(integer) 0 # 因为 name 已经存在，所以 set 创建不成功&gt; get name&quot;codehole&quot; # 没有改变计数123456789101112&gt; set age 30OK&gt; incr age(integer) 31&gt; incrby age 5(integer) 36&gt; incrby age -5(integer) 31&gt; set codehole 9223372036854775807 # Long.MaxOK&gt; incr codehole(error) ERR increment or decrement would overflow2.2 list (列表)Redis的列表相当于Java的ArrayList，是由链表组成的，所以插入和删除较快，但是查询比较慢。list中的最后一个元素弹出后，该数据结构就被删除，内存也被回收了。右边进左边出：队列123456789101112&gt; rpush books python java golang(integer) 3&gt; llen books(integer) 3&gt; lpop books&quot;python&quot;&gt; lpop books&quot;java&quot;&gt; lpop books&quot;golang&quot;&gt; lpop books(nil)右边进右边出：栈12345678910&gt; rpush books python java golang(integer) 3&gt; rpop books&quot;golang&quot;&gt; rpop books&quot;java&quot;&gt; rpop books&quot;python&quot;&gt; rpop books(nil)慢操作lindex 相当于 Java 链表的get(int index)方法，它需要对链表进行遍历，性能随着参数index增大而变差。ltrim 和字面上的含义不太一样，个人觉得它叫 lretain(保留) 更合适一些，因为 ltrim 跟的两个参数start_index和end_index定义了一个区间，在这个区间内的值，ltrim 要保留，区间之外统统砍掉。我们可以通过ltrim来实现一个定长的链表，这一点非常有用。index 可以为负数，index=-1表示倒数第一个元素，同样index=-2表示倒数第二个元素。1234567891011121314151617&gt; rpush books python java golang(integer) 3&gt; lindex books 1 # O(n) 慎用&quot;java&quot;&gt; lrange books 0 -1 # 获取所有元素，O(n) 慎用1) &quot;python&quot;2) &quot;java&quot;3) &quot;golang&quot;&gt; ltrim books 1 -1 # O(n) 慎用OK&gt; lrange books 0 -11) &quot;java&quot;2) &quot;golang&quot;&gt; ltrim books 1 0 # 这其实是清空了整个列表，因为区间范围长度为负OK&gt; llen books(integer) 0底层数据结构Redis 底层存储的还不是一个简单的 linkedlist，而是称之为快速链表 quicklist 的一个结构。首先在列表元素较少的情况下会使用一块连续的内存存储，这个结构是 ziplist，也即是压缩列表。它将所有的元素紧挨着一起存储，分配的是一块连续的内存。当数据量比较多的时候才会改成 quicklist。因为普通的链表需要的附加指针空间太大，会比较浪费空间，而且会加重内存的碎片化。比如这个列表里存的只是 int 类型的数据，结构上还需要两个额外的指针 prev 和 next 。所以 Redis 将链表和 ziplist 结合起来组成了 quicklist。也就是将多个 ziplist 使用双向指针串起来使用。这样既满足了快速的插入删除性能，又不会出现太大的空间冗余。可以查看列表中的压缩列表和快速列表。2.3 hash (哈希)hash类比于Java中的HashMap，它是无序字典。内部实现结构上同 Java 的 HashMap 也是一致的，同样的数组 + 链表二维结构。第一维 hash 的数组位置碰撞时，就会将碰撞的元素使用链表串接起来。不同的是，Redis 的字典的值只能是字符串，另外它们 rehash 的方式不一样，因为 Java 的 HashMap 在字典很大时，rehash 是个耗时的操作，需要一次性全部 rehash。Redis 为了高性能，不能堵塞服务，所以采用了渐进式 rehash 策略。hash 结构也可以用来存储用户信息，不同于字符串一次性需要全部序列化整个对象，hash 可以对用户结构中的每个字段单独存储。这样当我们需要获取用户信息时可以进行部分获取。而以整个字符串的形式去保存用户信息的话就只能一次性全部读取，这样就会比较浪费网络流量。hash 也有缺点，hash 结构的存储消耗要高于单个字符串，到底该使用 hash 还是字符串，需要根据实际情况再三权衡。指令1234567891011121314151617181920212223&gt; hset books java &quot;think in java&quot; # 命令行的字符串如果包含空格，要用引号括起来(integer) 1&gt; hset books golang &quot;concurrency in go&quot;(integer) 1&gt; hset books python &quot;python cookbook&quot;(integer) 1&gt; hgetall books # entries()，key 和 value 间隔出现1) &quot;java&quot;2) &quot;think in java&quot;3) &quot;golang&quot;4) &quot;concurrency in go&quot;5) &quot;python&quot;6) &quot;python cookbook&quot;&gt; hlen books(integer) 3&gt; hget books java&quot;think in java&quot;&gt; hset books golang &quot;learning go programming&quot; # 因为是更新操作，所以返回 0(integer) 0&gt; hget books golang&quot;learning go programming&quot;&gt; hmset books java &quot;effective java&quot; python &quot;learning python&quot; golang &quot;modern golang programming&quot; # 批量 setOK同字符串一样，hash 结构中的单个子 key 也可以进行计数，它对应的指令是 hincrby，和 incr 使用基本一样。123# 老钱又老了一岁&gt; hincrby user-laoqian age 1(integer) 30关于字典的内部结构实现，可以查看「字典」内部。2.4 set((集合)set对比Java中的HashSet相似，内部value也唯一无序的。它的内部实现相当于一个特殊的字典，字典中所有的 value 都是一个值NULL。和list相同，当集合中最后一个元素移除之后，数据结构自动删除，内存被回收。可以在去重应用环境中。指令123456789101112131415161718&gt; sadd books python(integer) 1&gt; sadd books python # 重复(integer) 0&gt; sadd books java golang(integer) 2&gt; smembers books # 注意顺序，和插入的并不一致，因为 set 是无序的1) &quot;java&quot;2) &quot;python&quot;3) &quot;golang&quot;&gt; sismember books java # 查询某个 value 是否存在，相当于 contains(o)(integer) 1&gt; sismember books rust(integer) 0&gt; scard books # 获取长度相当于 count()(integer) 3&gt; spop books # 弹出一个&quot;java&quot;2.5 zset (有序集合)zset 可能是 Redis 提供的最为特色的数据结构，它也是在面试中面试官最爱问的数据结构。它类似于 Java 的 SortedSet 和 HashMap 的结合体，一方面它是一个 set，保证了内部 value 的唯一性，另一方面它可以给每个 value 赋予一个 score，代表这个 value 的排序权重。它的内部实现用的是一种叫做「跳跃列表」的数据结构。zset 中最后一个 value 被移除后，数据结构自动删除，内存被回收。指令123456789101112131415161718192021222324252627282930313233&gt; zadd books 9.0 &quot;think in java&quot;(integer) 1&gt; zadd books 8.9 &quot;java concurrency&quot;(integer) 1&gt; zadd books 8.6 &quot;java cookbook&quot;(integer) 1&gt; zrange books 0 -1 # 按 score 排序列出，参数区间为排名范围1) &quot;java cookbook&quot;2) &quot;java concurrency&quot;3) &quot;think in java&quot;&gt; zrevrange books 0 -1 # 按 score 逆序列出，参数区间为排名范围1) &quot;think in java&quot;2) &quot;java concurrency&quot;3) &quot;java cookbook&quot;&gt; zcard books # 相当于 count()(integer) 3&gt; zscore books &quot;java concurrency&quot; # 获取指定 value 的 score&quot;8.9000000000000004&quot; # 内部 score 使用 double 类型进行存储，所以存在小数点精度问题&gt; zrank books &quot;java concurrency&quot; # 排名(integer) 1&gt; zrangebyscore books 0 8.91 # 根据分值区间遍历 zset1) &quot;java cookbook&quot;2) &quot;java concurrency&quot;&gt; zrangebyscore books -inf 8.91 withscores # 根据分值区间 (-∞, 8.91] 遍历 zset，同时返回分值。inf 代表 infinite，无穷大的意思。1) &quot;java cookbook&quot;2) &quot;8.5999999999999996&quot;3) &quot;java concurrency&quot;4) &quot;8.9000000000000004&quot;&gt; zrem books &quot;java concurrency&quot; # 删除 value(integer) 1&gt; zrange books 0 -11) &quot;java cookbook&quot;2) &quot;think in java&quot;3.其他通用规则list/set/hash/zset 这四种数据结构是容器型数据结构，它们共享下面两条通用规则：create if not exists如果容器不存在，那就创建一个，再进行操作。比如 rpush 操作刚开始是没有列表的，Redis 就会自动创建一个，然后再 rpush 进去新元素。drop if no elements如果容器里元素没有了，那么立即删除元素，释放内存。这意味着 lpop 操作到最后一个元素，列表就消失了。过期时间Redis 所有的数据结构都可以设置过期时间，时间到了，Redis 会自动删除相应的对象。需要注意的是过期是以对象为单位，比如一个 hash 结构的过期是整个 hash 对象的过期，而不是其中的某个子 key。还有一个需要特别注意的地方是如果一个字符串已经设置了过期时间，然后你调用了 set 方法修改了它，它的过期时间会消失。","categories":[{"name":"Redis","slug":"Redis","permalink":"http://localhost:4000/categories/Redis/"},{"name":"基本结构","slug":"Redis/基本结构","permalink":"http://localhost:4000/categories/Redis/基本结构/"}],"tags":[{"name":"redis","slug":"redis","permalink":"http://localhost:4000/tags/redis/"},{"name":"缓存","slug":"缓存","permalink":"http://localhost:4000/tags/缓存/"}]},{"title":"Java线程池的原理分析","slug":"Java线程池","date":"2019-06-16T14:25:02.000Z","updated":"2019-06-17T04:59:56.308Z","comments":true,"path":"2019/06/16/Java线程池/","link":"","permalink":"http://localhost:4000/2019/06/16/Java线程池/","excerpt":"","text":"Java线程池的原理分析1.简介随着并发的不断增加，单个线程的创建和销毁会带来大量的资源开销。通过线程池 我们可以方便的复用线程，避免了频繁创建和销毁线程所带来的开销。在应用上，线程池可应用在后端相关服务中。比如 Web 服务器，数据库服务器等。以 Web 服务器为例，假如 Web 服务器会收到大量短时的 HTTP 请求，如果此时我们简单的为每个 HTTP 请求创建一个处理线程，那么服务器的资源将会很快被耗尽。当然我们也可以自己去管理并复用已创建的线程，以限制资源的消耗量，但这样会使用程序的逻辑变复杂。好在，幸运的是，我们不必那样做。在 JDK 1.5 中，官方已经提供了强大的线程池工具类。通过使用这些工具类，我们可以用低廉的代价使用多线程技术。在Java用有一个Executors工具类，可以为我们创建一个线程池，其本质就是new了一个ThreadPoolExecutor对象。 觉得很有必要去学习一下线程池的相关原理。毕竟线程池除了要管理线程，还要管理任务，同时还要具备统计功能。所以多了解一点，还是可以扩充眼界的，同时也可以更为熟悉线程池技术。2.Executor继承关系线程池所采用的接口和类的结构如下图如上图，最顶层的接口 Executor 仅声明了一个方法execute。ExecutorService 接口在其父类接口基础上，声明了包含但不限于shutdown、submit、invokeAll、invokeAny 等方法。至于 ScheduledExecutorService 接口，则是声明了一些和定时任务相关的方法，比如 schedule和scheduleAtFixedRate。线程池的核心实现是在 ThreadPoolExecutor 类中，我们使用 Executors 调用newFixedThreadPool、newSingleThreadExecutor和newCachedThreadPool等方法创建线程池均是 ThreadPoolExecutor 类型。以上是对线程池继承体系的简单介绍，这里先让大家对线程池大致轮廓有一定的了解。接下来我会介绍一下线程池的实现原理，继续往下看吧。3.原理分析3.1核心关系分析3.1.1核心参数简介如上节所说，线程池的核心实现即 ThreadPoolExecutor 类。该类包含了几个核心属性，这些属性在可在构造方法进行初始化。在介绍核心属性前，我们先来看看 ThreadPoolExecutor 的构造方法，如下：12345678910111213141516171819202122public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue, ThreadFactory threadFactory, RejectedExecutionHandler handler) &#123; if (corePoolSize &lt; 0 || maximumPoolSize &lt;= 0 || maximumPoolSize &lt; corePoolSize || keepAliveTime &lt; 0) throw new IllegalArgumentException(); if (workQueue == null || threadFactory == null || handler == null) throw new NullPointerException(); this.corePoolSize = corePoolSize; this.maximumPoolSize = maximumPoolSize; this.workQueue = workQueue; this.keepAliveTime = unit.toNanos(keepAliveTime); this.threadFactory = threadFactory; this.handler = handler;&#125;如上所示，构造方法的参数即核心参数，这里我用一个表格来简要说明一下各个参数的意义。如下：参数说明corePoolSize核心线程数。当线程数小于该值时，线程池会优先创建新线程来执行新任务maximumPoolSize线程池所能维护的最大线程数keepAliveTime空闲线程的存活时间workQueue任务队列，用于缓存未执行的任务threadFactory线程工厂。可通过工厂为新建的线程设置更有意义的名字handler拒绝策略。当线程池和任务队列均处于饱和状态时，使用拒绝策略处理新任务。默认是 AbortPolicy，即直接抛出异常以上是各个参数的简介，下面我将会针对部分参数进行详细说明，继续往下看。3.1.2线程创建规则在 Java 线程池实现中，线程池所能创建的线程数量受限于 corePoolSize 和 maximumPoolSize 两个参数值。线程的创建时机则和 corePoolSize 以及 workQueue 两个参数有关。下面列举一下线程创建的4个规则（线程池中无空闲线程），如下：线程数量小于corePoolSize ，直接新创建线程处理任务线程数量大于等于corePoolSize ，workQueue 未满时，缓存新任务线程数量大于等于corePoolSize ，小于maximumPoolSize，且 workQueue 已满，则创建新线程处理新任务线程数量大于等于 maximumPoolSize，且 workQueue 已满，则使用拒绝策略处理新任务规则如下序号规则动作1线程数 &lt; corePoolSize创建新线程2线程数 &gt;= corePoolSize ，且 workQueue 未满缓存新任务3corePoolSize ≤ 线程数 ＜ maximumPoolSize，且 workQueue 已满创建新线程4线程数 ≥ maximumPoolSize，且 workQueue 已满使用拒绝策略处理3.1.3资源回收考虑到系统资源是有限的，对于线程池超出 corePoolSize 数量的空闲线程应进行回收操作。进行此操作存在一个问题，即回收时机。目前的实现方式是当线程空闲时间超过 keepAliveTime 后，进行回收。除了核心线程数之外的线程可以进行回收，核心线程内的空闲线程也可以进行回收。回收的前提是allowCoreThreadTimeOut属性被设置为 true，通过public void allowCoreThreadTimeOut(boolean) 方法可以设置属性值。3.1.4排队策略如3.1.2 线程创建规则一节中规则2所说，当线程数量大于等于 corePoolSize，workQueue 未满时，则缓存新任务。这里要考虑使用什么类型的容器缓存新任务，通过 JDK 文档介绍，我们可知道有3中类型的容器可供使用，分别是同步队列，有界队列和无界队列。对于有优先级的任务，这里还可以增加优先级队列。以上所介绍的4中类型的队列，对应的实现类如下：实现类类型说明SynchronousQueue同步队列该队列不存储元素，每个插入操作必须等待另一个线程调用移除操作，否则插入操作会一直阻塞ArrayBlockingQueue有界队列基于数组的阻塞队列，按照 FIFO 原则对元素进行排序LinkedBlockingQueue无界队列基于链表的阻塞队列，按照 FIFO 原则对元素进行排序PriorityBlockingQueue优先级队列具有优先级的阻塞队列3.1.5拒绝策略如3.1.2 线程创建规则一节中规则4所说，线程数量大于等于 maximumPoolSize，且 workQueue 已满，则使用拒绝策略处理新任务。Java 线程池提供了4中拒绝策略实现类，如下：实现类说明AbortPolicy （默认）丢弃新任务，并抛出 RejectedExecutionExceptionDiscardPolicy不做任何操作，直接丢弃新任务DiscardOldestPolicy丢弃队列队首的元素，并执行新任务CallerRunsPolicy由调用线程执行新任务以上4个拒绝策略中，AbortPolicy 是线程池实现类所使用的策略。我们也可以通过方法public void setRejectedExecutionHandler(RejectedExecutionHandler)修改线程池决绝策略。3.2 重要操作3.2.1线程的创建与复用在线程池的实现上，线程的创建是通过线程工厂接口ThreadFactory的实现类来完成的。默认情况下，线程池使用Executors.defaultThreadFactory()方法返回的线程工厂实现类。当然，我们也可以通过public void setThreadFactory(ThreadFactory)方法进行动态修改。具体细节这里就不多说了，并不复杂，大家可以自己去看下源码。在线程池中，线程的复用是线程池的关键所在。这就要求线程在执行完一个任务后，不能立即退出。对应到具体实现上，工作线程在执行完一个任务后，会再次到任务队列获取新的任务。如果任务队列中没有任务，且 keepAliveTime 也未被设置，工作线程则会被一致阻塞下去。通过这种方式即可实现线程复用。说完原理，再来看看线程的创建和复用的相关代码（基于 JDK 1.8），如下：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120private final class Worker extends AbstractQueuedSynchronizer implements Runnable &#123; /** * This class will never be serialized, but we provide a * serialVersionUID to suppress a javac warning. */ private static final long serialVersionUID = 6138294804551838833L; /** Thread this worker is running in. Null if factory fails. */ final Thread thread; /** Initial task to run. Possibly null. */ Runnable firstTask; /** Per-thread task counter */ volatile long completedTasks; /** * Creates with given first task and thread from ThreadFactory. * @param firstTask the first task (null if none) */ Worker(Runnable firstTask) &#123; setState(-1); // inhibit interrupts until runWorker this.firstTask = firstTask; // 调用线程工厂创建线程 this.thread = getThreadFactory().newThread(this); &#125; /** Delegates main run loop to outer runWorker */ public void run() &#123; //具体的执行 runWorker(this); &#125; // Lock methods // // The value 0 represents the unlocked state. // The value 1 represents the locked state. protected boolean isHeldExclusively() &#123; return getState() != 0; &#125; protected boolean tryAcquire(int unused) &#123; if (compareAndSetState(0, 1)) &#123; setExclusiveOwnerThread(Thread.currentThread()); return true; &#125; return false; &#125; protected boolean tryRelease(int unused) &#123; setExclusiveOwnerThread(null); setState(0); return true; &#125; public void lock() &#123; acquire(1); &#125; public boolean tryLock() &#123; return tryAcquire(1); &#125; public void unlock() &#123; release(1); &#125; public boolean isLocked() &#123; return isHeldExclusively(); &#125; void interruptIfStarted() &#123; Thread t; if (getState() &gt;= 0 &amp;&amp; (t = thread) != null &amp;&amp; !t.isInterrupted()) &#123; try &#123; t.interrupt(); &#125; catch (SecurityException ignore) &#123; &#125; &#125; &#125; &#125;//具体的执行final void runWorker(Worker w) &#123; Thread wt = Thread.currentThread(); Runnable task = w.firstTask; w.firstTask = null; w.unlock(); // allow interrupts boolean completedAbruptly = true; try &#123; // 循环从任务队列中获取新任务 while (task != null || (task = getTask()) != null) &#123; w.lock(); // If pool is stopping, ensure thread is interrupted; // if not, ensure thread is not interrupted. This // requires a recheck in second case to deal with // shutdownNow race while clearing interrupt if ((runStateAtLeast(ctl.get(), STOP) || (Thread.interrupted() &amp;&amp; runStateAtLeast(ctl.get(), STOP))) &amp;&amp; !wt.isInterrupted()) wt.interrupt(); try &#123; beforeExecute(wt, task); Throwable thrown = null; try &#123; // 执行新任务 task.run(); &#125; catch (RuntimeException x) &#123; thrown = x; throw x; &#125; catch (Error x) &#123; thrown = x; throw x; &#125; catch (Throwable x) &#123; thrown = x; throw new Error(x); &#125; finally &#123; afterExecute(task, thrown); &#125; &#125; finally &#123; task = null; w.completedTasks++; w.unlock(); &#125; &#125; completedAbruptly = false; &#125; finally &#123; // 线程退出后，进行后续处理 processWorkerExit(w, completedAbruptly); &#125; &#125;3.2.2 提交任务通常情况下，我们可以通过线程池的submit方法提交任务。被提交的任务可能会立即执行，也可能会被缓存或者被拒绝。任务的处理流程如下图所示：上面的流程图不是很复杂，下面再来看看流程图对应的代码，如下：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106+---- AbstractExecutorService.javapublic Future&lt;?&gt; submit(Runnable task) &#123; if (task == null) throw new NullPointerException(); // 创建任务 RunnableFuture&lt;Void&gt; ftask = newTaskFor(task, null); // 提交任务 execute(ftask); return ftask;&#125;+---- ThreadPoolExecutor.javapublic void execute(Runnable command) &#123; if (command == null) throw new NullPointerException(); int c = ctl.get(); // 如果工作线程数量 &lt; 核心线程数，则创建新线程 if (workerCountOf(c) &lt; corePoolSize) &#123; // 添加工作者对象 if (addWorker(command, true)) return; c = ctl.get(); &#125; // 缓存任务，如果队列已满，则 offer 方法返回 false。否则，offer 返回 true if (isRunning(c) &amp;&amp; workQueue.offer(command)) &#123; int recheck = ctl.get(); if (! isRunning(recheck) &amp;&amp; remove(command)) reject(command); else if (workerCountOf(recheck) == 0) addWorker(null, false); &#125; // 添加工作者对象，并在 addWorker 方法中检测线程数是否小于最大线程数 else if (!addWorker(command, false)) // 线程数 &gt;= 最大线程数，使用拒绝策略处理任务 reject(command);&#125;private boolean addWorker(Runnable firstTask, boolean core) &#123; retry: for (;;) &#123; int c = ctl.get(); int rs = runStateOf(c); // Check if queue empty only if necessary. if (rs &gt;= SHUTDOWN &amp;&amp; ! (rs == SHUTDOWN &amp;&amp; firstTask == null &amp;&amp; ! workQueue.isEmpty())) return false; for (;;) &#123; int wc = workerCountOf(c); // 检测工作线程数与核心线程数或最大线程数的关系 if (wc &gt;= CAPACITY || wc &gt;= (core ? corePoolSize : maximumPoolSize)) return false; if (compareAndIncrementWorkerCount(c)) break retry; c = ctl.get(); // Re-read ctl if (runStateOf(c) != rs) continue retry; // else CAS failed due to workerCount change; retry inner loop &#125; &#125; boolean workerStarted = false; boolean workerAdded = false; Worker w = null; try &#123; // 创建工作者对象，细节参考上一节所贴代码 w = new Worker(firstTask); final Thread t = w.thread; if (t != null) &#123; final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try &#123; int rs = runStateOf(ctl.get()); if (rs &lt; SHUTDOWN || (rs == SHUTDOWN &amp;&amp; firstTask == null)) &#123; if (t.isAlive()) // precheck that t is startable throw new IllegalThreadStateException(); // 将 worker 对象添加到 workers 集合中 workers.add(w); int s = workers.size(); // 更新 largestPoolSize 属性 if (s &gt; largestPoolSize) largestPoolSize = s; workerAdded = true; &#125; &#125; finally &#123; mainLock.unlock(); &#125; if (workerAdded) &#123; // 开始执行任务 t.start(); workerStarted = true; &#125; &#125; &#125; finally &#123; if (! workerStarted) addWorkerFailed(w); &#125; return workerStarted;&#125;3.2.3 关闭线程池我们可以通过shutdown和shutdownNow两个方法关闭线程池。两个方法的区别在于，shutdown 会将线程池的状态设置为SHUTDOWN，同时该方法还会中断空闲线程。shutdownNow 则会将线程池状态设置为STOP，并尝试中断所有的线程。中断线程使用的是Thread.interrupt方法，未响应中断方法的任务是无法被中断的。最后，shutdownNow 方法会将未执行的任务全部返回。调用 shutdown 和 shutdownNow 方法关闭线程池后，就不能再向线程池提交新任务了。对于处于关闭状态的线程池，会使用拒绝策略处理新提交的任务。4.几种线程池一般情况下，我们并不直接使用 ThreadPoolExecutor 类创建线程池，而是通过 Executors 工具类去构建线程池。通过 Executors 工具类，我们可以构造5中不同的线程池。下面通过一个表格简单介绍一下几种线程池，如下：构造方法说明newFixedThreadPool(int nThreads)构建包含固定线程数的线程池，默认情况下，空闲线程不会被回收newCachedThreadPool()构建线程数不定的线程池，线程数量随任务量变动，空闲线程存活时间超过60秒后会被回收newSingleThreadExecutor()构建线程数为1的线程池，等价于 newFixedThreadPool(1) 所构造出的线程池newScheduledThreadPool(int corePoolSize)构建核心线程数为 corePoolSize，可执行定时任务的线程池newSingleThreadScheduledExecutor()等价于 newScheduledThreadPool(1)5.总结一般需要根据任务的类型来配置线程池大小：如果是CPU密集型任务，就需要尽量压榨CPU，参考值可以设为 NCPU+1；如果是IO密集型任务，参考值可以设置为2*NCPU。当然，这只是一个参考值，具体的设置还需要根据实际情况进行调整，比如可以先将线程池大小设置为参考值，再观察任务运行情况和系统负载、资源利用率来进行适当调整。参考http://developer.51cto.com/art/201203/321885.htmhttp://blog.csdn.net/cutesource/article/details/6061229http://blog.csdn.net/xieyuooo/article/details/8718741","categories":[{"name":"Java基础","slug":"Java基础","permalink":"http://localhost:4000/categories/Java基础/"},{"name":"并发","slug":"Java基础/并发","permalink":"http://localhost:4000/categories/Java基础/并发/"}],"tags":[{"name":"Java基础","slug":"Java基础","permalink":"http://localhost:4000/tags/Java基础/"},{"name":"开发","slug":"开发","permalink":"http://localhost:4000/tags/开发/"},{"name":"线程池","slug":"线程池","permalink":"http://localhost:4000/tags/线程池/"},{"name":"锁","slug":"锁","permalink":"http://localhost:4000/tags/锁/"}]},{"title":"简析限流算法","slug":"简析限流算法","date":"2019-06-15T15:24:02.000Z","updated":"2019-06-17T04:40:38.950Z","comments":true,"path":"2019/06/15/简析限流算法/","link":"","permalink":"http://localhost:4000/2019/06/15/简析限流算法/","excerpt":"","text":"1.简介限流顾名思义是限制流量，限制流量的目的是为了保障服务稳定运行，避免服务被流量冲垮。当流量超出服务处理能力时，部分请求将会被限流组件拦截。被拦截的请求可能会被丢弃，如果是 C 端请求，那么这个请求可能会被导向指定的错误页上，而不是生硬的拒绝。这里我们丢弃掉一部分请求，以保证大部分请求可以正常响应。如果我们不这样做，那么服务崩溃后，所有请求都将无法响应了。当一台机器崩溃后，该机器的所有流量将由其他机器承担，这样就会造成剩余机器压力增大，进而导致奔溃，最后形成雪崩。除此之外，服务崩溃还会造成数据不一致的严重问题，特别是一些敏感数据。比如对于电商网站，如果后台服务准备将某笔订单数据存入数据库时，服务突然崩溃，导致数据没有落库。这个时候，开发同学就要想办法修订数据了。综上，我们可以看出来限流的重要性。接下来，我将向大家介绍三种常用的限流算法，分别是计数器、漏桶算法和令牌桶算法。下面我们从最简单的计数器开始说起。2.限流算法2.1 计数器计数器算法的思想很简单，每当一个请求到来时，我们就将计数器加一，当计数器数值超过阈值后，就拒绝余下请求。一秒钟后，我们将计数器清零，开始新一轮的计数。计数器算法简单粗暴，易于实现。但是缺点也是有的，也就是所谓的”突刺现象”。举例说明一下，假如我们给计数器设置的阈值为100。系统瞬间内（比如10毫秒内）有200个请求到来，这个时候计数器只能放过其中的100个请求，余下的100个请求全部被拒绝掉。如果第二秒内没有请求到来，那么系统就处于空闲状态。也就是上一秒忙的要死，这一秒又闲的要死。如果我们能用一个容器将剩余的100个请求缓存起来，待计数器重置后再将这些请求放出来。这样系统在这两秒内的吞吐量就由100变成了200，提升了一倍。基于这个思考，下面我们再来看看漏桶算法。2.2 漏桶算法漏桶算法由流量容器、流量入口和出口组成。其中流量出口流速即为我们期望的限速值，比如 100 QPS。漏桶算法除了具备限流能力，还具备流量整型功能。下面我们通过一张图来了解漏桶算法。如上图，流入漏桶流量的流速是不恒定的，经过漏桶限速后，流出流量的速度是恒定的。需要说明的是，漏桶的容量是有限的，一旦流入流量超出漏桶容量，这部分流量只能被丢弃了。漏桶是一个比较好的限流整型工具，不过漏桶不能处理突发流量，一些观点认为这是它的一个缺点。不过如果较起真来，我觉得这个缺点是不成立的。毕竟漏桶本就是用来平滑流量的，如果支持突发，那么输出流量反而不平滑了。如果要找一种能够支持突发流量的限流算法，那么令牌桶算法可以满足需求2.3 令牌桶算法令牌桶和漏桶颇有几分相似，只不过令牌通里存放的是令牌。它的运行过程是这样的，一个令牌工厂按照设定值定期向令牌桶发放令牌。当令牌桶满了后，多出的令牌会被丢弃掉。每当一个请求到来时，该请求对应的线程会从令牌桶中取令牌。初期由于令牌桶中存放了很多个令牌，因此允许多个请求同时取令牌。当桶中没有令牌后，无法获取到令牌的请求可以丢弃，或者重试。下面我们来看一下的令牌桶示意图：尽管令牌桶允许突发流量，但突发流量速率 R1 + 限流速率 R2 不能超过系统最大的处理能力 Rt，即 R1 + R2 ≤ Rt,否则会冲垮系统3.RateLimiter简介Google开源工具包Guava提供了限流工具类RateLimiter,该类基于令牌桶算法(Token Bucket)来完成限流,非常易于使用.RateLimiter经常用于限制对一些物理资源或者逻辑资源的访问速率.它支持两种获取permits接口,一种是如果拿不到立刻返回false,一种会阻塞等待一段时间看能不能拿到.RateLimiter和Java中的信号量(java.util.concurrent.Semaphore)类似,Semaphore通常用于限制并发量.源码注释中的一个例子,比如我们有很多任务需要执行,但是我们不希望每秒超过两个任务执行,那么我们就可以使用RateLimiter:1234567final RateLimiter rateLimiter = RateLimiter.create(2.0);void submitTasks(List&lt;Runnable&gt; tasks, Executor executor) &#123;for (Runnable task : tasks) &#123; rateLimiter.acquire(); // may wait executor.execute(task); &#125;&#125;另外一个例子,假如我们会产生一个数据流,然后我们想以每秒5kb的速度发送出去.我们可以每获取一个令牌(permit)就发送一个byte的数据,这样我们就可以通过一个每秒5000个令牌的RateLimiter来实现:12345final RateLimiter rateLimiter = RateLimiter.create(5000.0);void submitPacket(byte[] packet) &#123; rateLimiter.acquire(packet.length); networkService.send(packet);&#125;4.其他限流器ASP.NET版本的一个比较成熟限流器:WebApiThrottle 参考：http://www.cnblogs.com/mushroom/archive/2015/07/21/4659200.htmlhttps://github.com/springside/springside4/wiki/Rate-Limiterhttps://en.wikipedia.org/wiki/Token_buckethttps://en.wikipedia.org/wiki/Leaky_bucket5.总结以上就是本篇文章的全部内容。本篇文章简单分析几种常见限流算法的运行过程，限于能力原因，文章若有错误不妥之处还请指明。好了，本篇文章到这里就结束了，感谢大家的阅读。","categories":[{"name":"中间件","slug":"中间件","permalink":"http://localhost:4000/categories/中间件/"},{"name":"限流组件","slug":"中间件/限流组件","permalink":"http://localhost:4000/categories/中间件/限流组件/"}],"tags":[{"name":"限流组件","slug":"限流组件","permalink":"http://localhost:4000/tags/限流组件/"}]},{"title":"三种分布式锁实现","slug":"三种分布式锁实现","date":"2019-06-15T14:24:02.000Z","updated":"2019-06-17T04:45:11.514Z","comments":true,"path":"2019/06/15/三种分布式锁实现/","link":"","permalink":"http://localhost:4000/2019/06/15/三种分布式锁实现/","excerpt":"","text":"1.简介对于单机模式，多个线程对一个共享变量进行访问和修改时， 我们可以采用Java多线程进行处理，所有的请求会分配到本机的JVM内部，然后映射到操作系统进行处理。随着业务的发展，需要对服务进行集群，一个应用会部署到不同的机器上，共享数据会在不同机器的不同JVM内存，同时不同机器的中的变量也是不存在共享，也不具有可见性，如果不加以控制的话，处理的得到的结果也许不是我们所期望的值。为了保证同一时间内，同一个方法或者属性变量在高并发的情况下只会被同一个线程执行，在传统的单机模式下，采用Java并发处理包（如ReentrantLock或Synchronized)进行互斥控制即可。但是对于分布式集群系统中，由于多线程分布在不同的机器上，原单机部署情况下的并发控制锁策略失效，单纯的Java API并不能提供分布式锁的能力。为了解决这个问题就需要一种跨JVM的互斥机制来控制共享资源的访问，这就是分布式锁要解决的问题！2.分布式锁具备哪些条件在分布式系统环境下，一个方法在同一时间只能被一个机器的一个线程执行；高可用的获取锁与释放锁；高性能的获取锁与释放锁；具备可重入特性；具备锁失效机制，防止死锁；具备非阻塞锁特性，即没有获取到锁将直接返回获取锁失败。3.分布式锁的三种实现方式3.1 基于数据库实现3.1.1 基于数据库表的实现要实现分布式锁，最简单的方式是直接创建一张锁表，然后通过操作该表的数据来实现。当我们要锁住某个方法或资源时，我们就在该表中增加一条记录，想要释放锁的时候就删除这条记录。创建这样一张数据库表：12345678CREATE TABLE `methodLock` ( `id` int(11) NOT NULL AUTO_INCREMENT COMMENT &apos;主键&apos;, `method_name` varchar(64) NOT NULL DEFAULT &apos;&apos; COMMENT &apos;锁定的方法名&apos;, `desc` varchar(1024) NOT NULL DEFAULT &apos;备注信息&apos;, `update_time` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT &apos;保存数据时间，自动生成&apos;, PRIMARY KEY (`id`), UNIQUE KEY `uidx_method_name` (`method_name `) USING BTREE) ENGINE=InnoDB DEFAULT CHARSET=utf8 COMMENT=&apos;锁定中的方法&apos;;当我们想要锁住某个方法时，执行以下SQL：1insert into methodLock(method_name,desc) values (‘method_name’,‘desc’)因为我们对method_name做了唯一性约束，这里如果有多个请求同时提交到数据库的话，数据库会保证只有一个操作可以成功，那么我们就可以认为操作成功的那个线程获得了该方法的锁，可以执行方法体内容。当方法执行完毕之后，想要释放锁的话，需要执行以下Sql:1delete from methodLock where method_name =&apos;method_name&apos;上面这种简单的实现有以下几个问题：这把锁强依赖数据库的可用性，数据库是一个单点，一旦数据库挂掉，会导致业务系统不可用。这把锁没有失效时间，一旦解锁操作失败，就会导致锁记录一直在数据库中，其他线程无法再获得到锁。这把锁只能是非阻塞的，因为数据的insert操作，一旦插入失败就会直接报错。没有获得锁的线程并不会进入排队队列，要想再次获得锁就要再次触发获得锁操作。这把锁是非重入的，同一个线程在没有释放锁之前无法再次获得该锁。因为数据中数据已经存在了。针对上面的问题，可以采用以下方式数据库是单点？搞两个数据库，数据之前双向同步。一旦挂掉快速切换到备库上。没有失效时间？只要做一个定时任务，每隔一定时间把数据库中的超时数据清理一遍。非阻塞的？搞一个while循环，直到insert成功再返回成功。非重入的？在数据库表中加个字段，记录当前获得锁的机器的主机信息和线程信息，那么下次再获取锁的时候先查询数据库，如果当前机器的主机信息和线程信息在数据库可以查到的话，直接把锁分配给他就可以了。3.1.2 基于数据库表的排他锁除了可以通过增删操作数据表中的记录以外，其实还可以借助数据中自带的锁来实现分布式的锁。我们还用刚刚创建的那张数据库表。可以通过数据库的排他锁来实现分布式锁。 基于MySql的InnoDB引擎，可以使用以下方法来实现加锁操作：123456789101112131415public boolean lock()&#123; connection.setAutoCommit(false) while(true)&#123; try&#123; result = select * from methodLock where method_name=xxx for update; if(result==null)&#123; return true; &#125; &#125;catch(Exception e)&#123; &#125; sleep(1000); &#125; return false;&#125;在查询语句后面增加for update，数据库会在查询过程中给数据库表增加排他锁（这里再多提一句，InnoDB引擎在加锁的时候，只有通过索引进行检索的时候才会使用行级锁，否则会使用表级锁。这里我们希望使用行级锁，就要给method_name添加索引，值得注意的是，这个索引一定要创建成唯一索引，否则会出现多个重载方法之间无法同时被访问的问题。重载方法的话建议把参数类型也加上。）。当某条记录被加上排他锁之后，其他线程无法再在该行记录上增加排他锁。我们可以认为获得排它锁的线程即可获得分布式锁，当获取到锁之后，可以执行方法的业务逻辑，执行完方法之后，再通过以下方法解锁：123public void unlock()&#123; connection.commit();&#125;通过connection.commit()操作来释放锁。这种方法可以有效的解决上面提到的无法释放锁和阻塞锁的问题。阻塞锁？ for update语句会在执行成功后立即返回，在执行失败时一直处于阻塞状态，直到成功。锁定之后服务宕机，无法释放？使用这种方式，服务宕机之后数据库会自己把锁释放掉。但是还是无法直接解决数据库单点和可重入问题。这里还可能存在另外一个问题，虽然我们对method_name 使用了唯一索引，并且显示使用for update来使用行级锁。但是，MySql会对查询进行优化，即便在条件中使用了索引字段，但是否使用索引来检索数据是由 MySQL 通过判断不同执行计划的代价来决定的，如果 MySQL 认为全表扫效率更高，比如对一些很小的表，它就不会使用索引，这种情况下 InnoDB 将使用表锁，而不是行锁。如果发生这种情况就悲剧了。还有一个问题，就是我们要使用排他锁来进行分布式锁的lock，那么一个排他锁长时间不提交，就会占用数据库连接。一旦类似的连接变得多了，就可能把数据库连接池撑爆3.1.3总结总结一下使用数据库来实现分布式锁的方式，这两种方式都是依赖数据库的一张表，一种是通过表中的记录的存在情况确定当前是否有锁存在，另外一种是通过数据库的排他锁来实现分布式锁。数据库实现分布式锁的优点是直接借助数据库，容易理解，方便使用。但是会有各种各样的问题，在解决问题的过程中会使整个方案变得越来越复杂，另外操作操作数据库需要一定的开销，性能问题需要考虑。使用数据库的行级锁并不一定靠谱，尤其是当我们的锁表并不大的时候。3.2 基于redis实现3.2.1 加锁代码代码如下1234567891011121314151617181920212223242526public class RedisTool &#123; private static final String LOCK_SUCCESS = \"OK\"; private static final String SET_IF_NOT_EXIST = \"NX\"; private static final String SET_WITH_EXPIRE_TIME = \"PX\"; /** * 尝试获取分布式锁 * @param jedis Redis客户端 * @param lockKey 锁 * @param requestId 请求标识 * @param expireTime 超期时间 * @return 是否获取成功 */ public static boolean tryGetDistributedLock(Jedis jedis, String lockKey, String requestId, int expireTime) &#123; String result = jedis.set(lockKey, requestId, SET_IF_NOT_EXIST, SET_WITH_EXPIRE_TIME, expireTime); if (LOCK_SUCCESS.equals(result)) &#123; return true; &#125; return false; &#125;&#125;可以看到，我们加锁就一行代码：jedis.set(String key, String value, String nxxx, String expx, int time)，这个set()方法一共有五个形参：第一个为key，我们使用key来当锁，因为key是唯一的。第二个为value，我们传的是requestId，很多童鞋可能不明白，有key作为锁不就够了吗，为什么还要用到value？原因就是我们在上面讲到可靠性时，分布式锁要满足第四个条件解铃还须系铃人，通过给value赋值为requestId，我们就知道这把锁是哪个请求加的了，在解锁的时候就可以有依据。requestId可以使用UUID.randomUUID().toString()方法生成。第三个为nxxx，这个参数我们填的是NX，意思是SET IF NOT EXIST，即当key不存在时，我们进行set操作；若key已经存在，则不做任何操作；第四个为expx，这个参数我们传的是PX，意思是我们要给这个key加一个过期的设置，具体时间由第五个参数决定。第五个为time，与第四个参数相呼应，代表key的过期时间。总的来说，执行上面的set()方法就只会导致两种结果：1. 当前没有锁（key不存在），那么就进行加锁操作，并对锁设置个有效期，同时value表示加锁的客户端。2. 已有锁存在，不做任何操作。心细的童鞋就会发现了，我们的加锁代码满足我们可靠性里描述的三个条件。首先，set()加入了NX参数，可以保证如果已有key存在，则函数不会调用成功，也就是只有一个客户端能持有锁，满足互斥性。其次，由于我们对锁设置了过期时间，即使锁的持有者后续发生崩溃而没有解锁，锁也会因为到了过期时间而自动解锁（即key被删除），不会发生死锁。最后，因为我们将value赋值为requestId，代表加锁的客户端请求标识，那么在客户端在解锁的时候就可以进行校验是否是同一个客户端。由于我们只考虑Redis单机部署的场景，所以容错性我们暂不考虑。比较常见的错误示例就是使用jedis.setnx()和jedis.expire()组合实现加锁，代码如下：123456789public static void wrongGetLock1(Jedis jedis, String lockKey, String requestId, int expireTime) &#123; Long result = jedis.setnx(lockKey, requestId); if (result == 1) &#123; // 若在这里程序突然崩溃，则无法设置过期时间，将发生死锁 jedis.expire(lockKey, expireTime); &#125;&#125;setnx()方法作用就是SET IF NOT EXIST，expire()方法就是给锁加一个过期时间。乍一看好像和前面的set()方法结果一样，然而由于这是两条Redis命令，不具有原子性，如果程序在执行完setnx()之后突然崩溃，导致锁没有设置过期时间。那么将会发生死锁。网上之所以有人这样实现，是因为低版本的jedis并不支持多参数的set()方法。3.2.2解锁代码代码如下123456789101112131415161718192021222324public class RedisTool &#123; private static final Long RELEASE_SUCCESS = 1L; /** * 释放分布式锁 * @param jedis Redis客户端 * @param lockKey 锁 * @param requestId 请求标识 * @return 是否释放成功 */ public static boolean releaseDistributedLock(Jedis jedis, String lockKey, String requestId) &#123; String script = \"if redis.call('get', KEYS[1]) == ARGV[1] then return redis.call('del', KEYS[1]) else return 0 end\"; Object result = jedis.eval(script, Collections.singletonList(lockKey), Collections.singletonList(requestId)); if (RELEASE_SUCCESS.equals(result)) &#123; return true; &#125; return false; &#125;&#125;从上面可以看到，我们解锁只需要两行代码就搞定了！第一行代码，我们写了一个简单的Lua脚本代码，上一次见到这个编程语言还是在《黑客与画家》里，没想到这次居然用上了。第二行代码，我们将Lua代码传到jedis.eval()方法里，并使参数KEYS[1]赋值为lockKey，ARGV[1]赋值为requestId。eval()方法是将Lua代码交给Redis服务端执行。那么这段Lua代码的功能是什么呢？其实很简单，首先获取锁对应的value值，检查是否与requestId相等，如果相等则删除锁（解锁）。那么为什么要使用Lua语言来实现呢？因为要确保上述操作是原子性的 。那么为什么执行eval()方法可以确保原子性，源于Redis的特性。简单来说，就是在eval命令执行Lua代码的时候，Lua代码将被当成一个命令去执行，并且直到eval命令执行完成，Redis才会执行其他命令。最常见的解锁代码就是直接使用jedis.del()方法删除锁，这种不先判断锁的拥有者而直接解锁的方式，会导致任何客户端都可以随时进行解锁，即使这把锁不是它的。3.2.3总结如何使用Java代码正确实现Redis分布式锁，对于加锁和解锁也分别给出了两个比较经典的错误。其实想要通过Redis实现分布式锁并不难，只要保证能满足可靠性里的四个条件。互联网虽然给我们带来了方便，只要有问题就可以google，然而网上的答案一定是对的吗？其实不然，所以我们更应该时刻保持着质疑精神，多想多验证。如果你的项目中Redis是多机部署的，那么可以尝试使用Redisson实现分布式锁。3.3 基于zookeeper实现基于zookeeper临时有序节点可以实现的分布式锁。大致思想即为：每个客户端对某个方法加锁时，在zookeeper上的与该方法对应的指定节点的目录下，生成一个唯一的瞬时有序节点。 判断是否获取锁的方式很简单，只需要判断有序节点中序号最小的一个。 当释放锁的时候，只需将这个瞬时节点删除即可。同时，其可以避免服务宕机导致的锁无法释放，而产生的死锁问题。来看下Zookeeper能不能解决前面提到的问题。锁无法释放？使用Zookeeper可以有效的解决锁无法释放的问题，因为在创建锁的时候，客户端会在ZK中创建一个临时节点，一旦客户端获取到锁之后突然挂掉（Session连接断开），那么这个临时节点就会自动删除掉。其他客户端就可以再次获得锁。非阻塞锁？使用Zookeeper可以实现阻塞的锁，客户端可以通过在ZK中创建顺序节点，并且在节点上绑定监听器，一旦节点有变化，Zookeeper会通知客户端，客户端可以检查自己创建的节点是不是当前所有节点中序号最小的，如果是，那么自己就获取到锁，便可以执行业务逻辑了。不可重入？使用Zookeeper也可以有效的解决不可重入的问题，客户端在创建节点的时候，把当前客户端的主机信息和线程信息直接写入到节点中，下次想要获取锁的时候和当前最小的节点中的数据比对一下就可以了。如果和自己的信息一样，那么自己直接获取到锁，如果不一样就再创建一个临时的顺序节点，参与排队。单点问题？使用Zookeeper可以有效的解决单点问题，ZK是集群部署的，只要集群中有半数以上的机器存活，就可以对外提供服务。可以直接使用zookeeper第三方库Curator客户端，这个客户端中封装了一个可重入的锁服务。123456789101112131415161718public boolean tryLock(long timeout, TimeUnit unit) throws InterruptedException &#123; try &#123; return interProcessMutex.acquire(timeout, unit); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; return true;&#125;public boolean unlock() &#123; try &#123; interProcessMutex.release(); &#125; catch (Throwable e) &#123; log.error(e.getMessage(), e); &#125; finally &#123; executorService.schedule(new Cleaner(client, path), delayTimeForClean, TimeUnit.MILLISECONDS); &#125; return true;&#125;Curator提供的InterProcessMutex是分布式锁的实现。acquire方法用户获取锁，release方法用于释放锁。使用ZK实现的分布式锁好像完全符合了本文开头我们对一个分布式锁的所有期望。但是，其实并不是，Zookeeper实现的分布式锁其实存在一个缺点，那就是性能上可能并没有缓存服务那么高。因为每次在创建锁和释放锁的过程中，都要动态创建、销毁瞬时节点来实现锁功能。ZK中创建和删除节点只能通过Leader服务器来执行，然后将数据同不到所有的Follower机器上。其实，使用Zookeeper也有可能带来并发问题，只是并不常见而已。考虑这样的情况，由于网络抖动，客户端可ZK集群的session连接断了，那么zk以为客户端挂了，就会删除临时节点，这时候其他客户端就可以获取到分布式锁了。就可能产生并发问题。这个问题不常见是因为zk有重试机制，一旦zk集群检测不到客户端的心跳，就会重试，Curator客户端支持多种重试策略。多次重试之后还不行的话才会删除临时节点。（所以，选择一个合适的重试策略也比较重要，要在锁的粒度和并发之间找一个平衡。）使用Zookeeper实现分布式锁的优点有效的解决单点问题，不可重入问题，非阻塞问题以及锁无法释放的问题。实现起来较为简单。使用Zookeeper实现分布式锁的缺点性能上不如使用缓存实现分布式锁。 需要对ZK的原理有所了解。4. 总结上面几种方式，哪种方式都无法做到完美。就像CAP一样，在复杂性、可靠性、性能等方面无法同时满足，所以，根据不同的应用场景选择最适合自己的才是王道。从理解的难易程度角度（从低到高）数据库 &gt; 缓存 &gt; Zookeeper从实现的复杂性角度（从低到高）Zookeeper &gt;= 缓存 &gt; 数据库从性能角度（从高到低）缓存 &gt; Zookeeper &gt;= 数据库从可靠性角度（从高到低）Zookeeper &gt; 缓存 &gt; 数据库参考https://blog.csdn.net/wuzhiwei549/article/details/80692278https://www.hollischuang.com/archives/1716","categories":[{"name":"中间件","slug":"中间件","permalink":"http://localhost:4000/categories/中间件/"},{"name":"分布式","slug":"中间件/分布式","permalink":"http://localhost:4000/categories/中间件/分布式/"}],"tags":[{"name":"锁","slug":"锁","permalink":"http://localhost:4000/tags/锁/"},{"name":"中间件","slug":"中间件","permalink":"http://localhost:4000/tags/中间件/"},{"name":"分布式","slug":"分布式","permalink":"http://localhost:4000/tags/分布式/"}]},{"title":"Hello World","slug":"hello-world","date":"2019-06-14T13:48:34.388Z","updated":"2019-06-16T07:30:14.246Z","comments":true,"path":"2019/06/14/hello-world/","link":"","permalink":"http://localhost:4000/2019/06/14/hello-world/","excerpt":"","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub.Quick StartCreate a new post1$ hexo new \"My New Post\"More info: WritingRun server1$ hexo serverMore info: ServerGenerate static files1$ hexo generateMore info: GeneratingDeploy to remote sites1$ hexo deployMore info: Deployment","categories":[],"tags":[]}]}